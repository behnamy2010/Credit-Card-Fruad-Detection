{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gRu9kpkYyztz"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn.metrics as metrique\n",
    "from pandas import Series\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "#from tensorflow.keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,GRU, Dense, Embedding, Dropout,Input, Attention, Layer, Concatenate, Permute, Dot, Multiply, Flatten\n",
    "from tensorflow.keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from tensorflow.keras import backend as K, regularizers, Model, metrics\n",
    "from tensorflow.keras.backend import cast\n",
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('324 X_resampled  + randomly distributed Gan + EllipticEnvelope+ duplicate remover.csv', na_filter=True)\n",
    "y_train = pd.read_csv('324 y_resampled  + randomly distributed Gan + EllipticEnvelope+ duplicate remover.csv', na_filter=True)\n",
    "X_test = pd.read_csv('324 test  X_resampled  + Gan + EllipticEnvelope.csv', na_filter=True)\n",
    "y_test = pd.read_csv('324 test  y_resampled  + Gan + EllipticEnvelope.csv', na_filter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0,X_train1=np.array_split(X_train,n)\n",
    "y_train0,y_train1=np.array_split(y_train,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    88719\n",
       "1.0      165\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train0.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((98761, 18), (98760, 18))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train0.shape,X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((98761,), (98760,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train0.shape,y_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0 = StandardScaler().fit_transform(X_train0)\n",
    "X_train1 = StandardScaler().fit_transform(X_train1)\n",
    "X_test=StandardScaler().fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train0,X_val0,y_train0,y_val0 = train_test_split(X_train0, y_train0, test_size=0.1)\n",
    "X_train1,X_val1,y_train1,y_val1 = train_test_split(X_train1, y_train1, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "eN6iBsXh0UJj"
   },
   "outputs": [],
   "source": [
    "def making_data (X_train,X_val,X_test,y_train,y_val,y_test):\n",
    "    # X_train et X_val sont des dataframe qui contient les features\n",
    "    train_GRU_X=X_train\n",
    "    val_GRU_X=X_val\n",
    "    test_GRU_X=X_test\n",
    "\n",
    "    ## Reshape input to be 3D [samples, timesteps, features] (format requis par GRU)\n",
    "    train_GRU_X = train_GRU_X.reshape((train_GRU_X.shape[0], 1, train_GRU_X.shape[1]))\n",
    "    val_GRU_X = val_GRU_X.reshape((val_GRU_X.shape[0], 1, val_GRU_X.shape[1]))\n",
    "    test_GRU_X = test_GRU_X.reshape((test_GRU_X.shape[0], 1, test_GRU_X.shape[1]))\n",
    "\n",
    "    ## Recuperation des labels\n",
    "    train_GRU_y=y_train\n",
    "    val_GRU_y=y_val\n",
    "    test_GRU_y=y_test\n",
    "    return train_GRU_X,val_GRU_X,test_GRU_X,train_GRU_y,val_GRU_y,test_GRU_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "45/45 [==============================] - 3s 19ms/step - loss: 0.5824 - accuracy: 0.8361 - val_loss: 0.4440 - val_accuracy: 0.9903\n",
      "Epoch 2/200\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.3456 - accuracy: 0.9904 - val_loss: 0.2152 - val_accuracy: 0.9989\n",
      "Epoch 3/200\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.1688 - accuracy: 0.9979 - val_loss: 0.0960 - val_accuracy: 0.9986\n",
      "Epoch 4/200\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0844 - accuracy: 0.9984 - val_loss: 0.0489 - val_accuracy: 0.9987\n",
      "Epoch 5/200\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0481 - accuracy: 0.9988 - val_loss: 0.0294 - val_accuracy: 0.9990\n",
      "Epoch 6/200\n",
      "45/45 [==============================] - 1s 12ms/step - loss: 0.0313 - accuracy: 0.9990 - val_loss: 0.0201 - val_accuracy: 0.9990\n",
      "Epoch 7/200\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0221 - accuracy: 0.9990 - val_loss: 0.0151 - val_accuracy: 0.9990\n",
      "Epoch 8/200\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0169 - accuracy: 0.9991 - val_loss: 0.0121 - val_accuracy: 0.9992\n",
      "Epoch 9/200\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.0133 - accuracy: 0.9991 - val_loss: 0.0103 - val_accuracy: 0.9992\n",
      "Epoch 10/200\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.0112 - accuracy: 0.9992 - val_loss: 0.0091 - val_accuracy: 0.9992\n",
      "Epoch 11/200\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.0097 - accuracy: 0.9992 - val_loss: 0.0082 - val_accuracy: 0.9992\n",
      "Epoch 12/200\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.0088 - accuracy: 0.9990 - val_loss: 0.0077 - val_accuracy: 0.9992\n",
      "Epoch 13/200\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.0076 - accuracy: 0.9992 - val_loss: 0.0072 - val_accuracy: 0.9992\n",
      "Epoch 14/200\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.0069 - val_accuracy: 0.9992\n",
      "Epoch 15/200\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 0.9992\n",
      "Epoch 16/200\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0059 - accuracy: 0.9993 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
      "Epoch 17/200\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
      "Epoch 18/200\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0062 - val_accuracy: 0.9992\n",
      "Epoch 19/200\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
      "Epoch 20/200\n",
      "45/45 [==============================] - 1s 11ms/step - loss: 0.0049 - accuracy: 0.9993 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
      "Epoch 21/200\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.0046 - accuracy: 0.9993 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
      "Epoch 22/200\n",
      "45/45 [==============================] - 0s 11ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0058 - val_accuracy: 0.9992\n",
      "Epoch 23/200\n",
      "15/45 [=========>....................] - ETA: 0s - loss: 0.0049 - accuracy: 0.9992"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-970fb0da500f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmodel0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sigmoid'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mhistory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_GRU_X0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_GRU_y0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_GRU_X0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_GRU_y0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1181\u001b[0m                 _r=1):\n\u001b[0;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1183\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1184\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    887\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3021\u001b[0m       (graph_function,\n\u001b[0;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3023\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3024\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1958\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1959\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1960\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1961\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_GRU_X0,val_GRU_X0,test_GRU_X,train_GRU_y0,val_GRU_y0,test_GRU_y=making_data (X_train0,X_val0,X_test,y_train0,y_val0,y_test)\n",
    "model0 = Sequential()\n",
    "model0.add(GRU(50,dropout=0.3,recurrent_dropout=0.2, return_sequences=True))\n",
    "model0.add(Dense(1, activation='sigmoid'))\n",
    "model0.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history=model0.fit(train_GRU_X0, train_GRU_y0,epochs=200,batch_size=2000, validation_data=(val_GRU_X0, val_GRU_y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lUAD5FIS3Z1I"
   },
   "outputs": [],
   "source": [
    "# predict probabilities for test set\n",
    "yhat_probs0 = model0.predict(test_GRU_X, verbose=0)> 0.5\n",
    "# reduce to 1d array\n",
    "yhat_probs0 = yhat_probs0[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_GRU_y, yhat_probs0)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_GRU_y, yhat_probs0)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_GRU_y, yhat_probs0)\n",
    "print('Recall: %f' % recall)\n",
    "#F1 = 2 * (precision * recall) / (precision + recall)\n",
    "f1=f1_score(test_GRU_y, yhat_probs0)\n",
    "print('f1: %f' % f1)\n",
    "\n",
    "print(classification_report(test_GRU_y, yhat_probs0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_GRU_X1,val_GRU_X1,test_GRU_X,train_GRU_y1,val_GRU_y1,test_GRU_y=making_data (X_train1,X_val1,X_test,y_train1,y_val1,y_test)\n",
    "model1 = Sequential()\n",
    "model1.add(GRU(50,dropout=0.3,recurrent_dropout=0.2, return_sequences=True))\n",
    "model1.add(Dense(1, activation='sigmoid'))\n",
    "model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history=model1.fit(train_GRU_X1, train_GRU_y1,epochs=200,batch_size=2000, validation_data=(val_GRU_X1, val_GRU_y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities for test set\n",
    "yhat_probs1 = model1.predict(test_GRU_X, verbose=0)> 0.5\n",
    "# reduce to 1d array\n",
    "yhat_probs1 = yhat_probs1[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_GRU_y, yhat_probs1)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_GRU_y, yhat_probs1)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_GRU_y, yhat_probs1)\n",
    "print('Recall: %f' % recall)\n",
    "#F1 = 2 * (precision * recall) / (precision + recall)\n",
    "f1=f1_score(test_GRU_y, yhat_probs1)\n",
    "print('f1: %f' % f1)\n",
    "\n",
    "print(classification_report(test_GRU_y, yhat_probs1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9eyxl7gxDjKk"
   },
   "outputs": [],
   "source": [
    "class attention(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(attention,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        self.W=self.add_weight(name=\"att_weight\",shape=(input_shape[-1],1),initializer=\"normal\")\n",
    "        self.b=self.add_weight(name=\"att_bias\",shape=(input_shape[1],1),initializer=\"zeros\")        \n",
    "        super(attention, self).build(input_shape)\n",
    "\n",
    "    def call(self,x):\n",
    "        et=K.squeeze(K.tanh(K.dot(x,self.W)+self.b),axis=-1)\n",
    "        at=K.softmax(et)\n",
    "        at=K.expand_dims(at,axis=-1)\n",
    "        output=x*at\n",
    "        return K.sum(output,axis=1)\n",
    "\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0],input_shape[-1])\n",
    "\n",
    "    def get_config(self):\n",
    "        return super(attention,self).get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs1=Input((1,18))\n",
    "att_in=GRU(50,return_sequences=True,dropout=0.3,recurrent_dropout=0.2)(inputs1)\n",
    "#att_in_1=GRU(50,return_sequences=True,dropout=0.3,recurrent_dropout=0.2)(att_in)\n",
    "att_out=attention()(att_in)\n",
    "outputs1=Dense(1,activation='sigmoid',trainable=True)(att_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vl454wu1C_sr"
   },
   "outputs": [],
   "source": [
    "model10=Model(inputs1,outputs1)\n",
    "model10.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvr6t9ivDryi"
   },
   "outputs": [],
   "source": [
    "history10=model10.fit(train_GRU_X0, train_GRU_y0,epochs=200,batch_size=3000, validation_data=(val_GRU_X0, val_GRU_y0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FowJ3_QvDsD6"
   },
   "outputs": [],
   "source": [
    "# predict probabilities for test set\n",
    "yhat_probs10 = model10.predict(test_GRU_X, verbose=0)> 0.5\n",
    "# reduce to 1d array\n",
    "yhat_probs10 = yhat_probs10[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91TI5B2sESst",
    "outputId": "0fe68a3e-4217-42d1-9619-472263c2d804"
   },
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_GRU_y, yhat_probs10)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_GRU_y, yhat_probs10)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_GRU_y, yhat_probs10)\n",
    "print('Recall: %f' % recall)\n",
    "#F1 = 2 * (precision * recall) / (precision + recall)\n",
    "f1=f1_score(test_GRU_y, yhat_probs10)\n",
    "print('f1: %f' % f1)\n",
    "\n",
    "print(classification_report(test_GRU_y, yhat_probs10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vl454wu1C_sr"
   },
   "outputs": [],
   "source": [
    "model11=Model(inputs1,outputs1)\n",
    "model11.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvr6t9ivDryi"
   },
   "outputs": [],
   "source": [
    "history11=model10.fit(train_GRU_X1, train_GRU_y1,epochs=200,batch_size=3000, validation_data=(val_GRU_X1, val_GRU_y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FowJ3_QvDsD6"
   },
   "outputs": [],
   "source": [
    "# predict probabilities for test set\n",
    "yhat_probs11 = model11.predict(test_GRU_X, verbose=0)> 0.5\n",
    "# reduce to 1d array\n",
    "yhat_probs11 = yhat_probs11[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91TI5B2sESst",
    "outputId": "0fe68a3e-4217-42d1-9619-472263c2d804"
   },
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_GRU_y, yhat_probs11)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_GRU_y, yhat_probs11)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_GRU_y, yhat_probs11)\n",
    "print('Recall: %f' % recall)\n",
    "#F1 = 2 * (precision * recall) / (precision + recall)\n",
    "f1=f1_score(test_GRU_y, yhat_probs11)\n",
    "print('f1: %f' % f1)\n",
    "\n",
    "print(classification_report(test_GRU_y, yhat_probs11))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = StandardScaler().fit_transform(X_train)\n",
    "X_train=X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_probs0 = model0.predict(X_train, verbose=0)\n",
    "yhat_probs1 = model1.predict(X_train, verbose=0)\n",
    "yhat_probs0=yhat_probs0.reshape(-1,1)\n",
    "yhat_probs1=yhat_probs1.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate((yhat_probs0,yhat_probs1),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier().fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_probs0 = model0.predict(test_GRU_X, verbose=0)\n",
    "yhat_probs1 = model1.predict(test_GRU_X, verbose=0)\n",
    "yhat_probs0=yhat_probs0.reshape(-1,1)\n",
    "yhat_probs1=yhat_probs1.reshape(-1,1)\n",
    "X_test=np.concatenate((yhat_probs0,yhat_probs1),axis=1)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_GRU_y, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_GRU_y, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_GRU_y, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "#F1 = 2 * (precision * recall) / (precision + recall)\n",
    "f1=f1_score(test_GRU_y, y_pred)\n",
    "print('f1: %f' % f1)\n",
    "\n",
    "print(classification_report(test_GRU_y, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## attension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_probs10 = model10.predict(X_train, verbose=0)\n",
    "yhat_probs11 = model11.predict(X_train, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.concatenate((yhat_probs10,yhat_probs11),axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier().fit(X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_probs10 = model10.predict(test_GRU_X, verbose=0)\n",
    "yhat_probs11 = model11.predict(test_GRU_X, verbose=0)\n",
    "X_test=np.concatenate((yhat_probs10,yhat_probs11),axis=1)\n",
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(test_GRU_y, y_pred)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(test_GRU_y, y_pred)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(test_GRU_y, y_pred)\n",
    "print('Recall: %f' % recall)\n",
    "#F1 = 2 * (precision * recall) / (precision + recall)\n",
    "f1=f1_score(test_GRU_y, y_pred)\n",
    "print('f1: %f' % f1)\n",
    "print(classification_report(test_GRU_y, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LSTM_Models.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
