{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22940673",
   "metadata": {
    "id": "22940673"
   },
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a4e93e5",
   "metadata": {
    "id": "7a4e93e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8ec4c89",
   "metadata": {
    "id": "e8ec4c89"
   },
   "outputs": [],
   "source": [
    "df1=pd.read_csv('fetureselectedcreditcard.csv')\n",
    "Target=pd.read_csv('Target.csv')\n",
    "\n",
    "lof_res=pd.read_csv('lof_res.csv')\n",
    "lof_t=pd.read_csv('lof_t.csv')\n",
    "lof_out=pd.read_csv('lof_out.csv')\n",
    "lof_ot=pd.read_csv('lof_ot.csv')\n",
    "\n",
    "isf_res=pd.read_csv('isf_res.csv')\n",
    "isf_t=pd.read_csv('isf_t.csv')\n",
    "isf_out=pd.read_csv('isf_out.csv')\n",
    "isf_ot=pd.read_csv('isf_ot.csv')\n",
    "\n",
    "ee_res=pd.read_csv('ee_res.csv')\n",
    "ee_t=pd.read_csv('ee_t.csv')\n",
    "ee_out=pd.read_csv('ee_out.csv')\n",
    "ee_ot=pd.read_csv('ee_ot.csv')\n",
    "\n",
    "\n",
    "osvm_res=pd.read_csv('osvm_res.csv')\n",
    "osvm_t=pd.read_csv('osvm_t.csv')\n",
    "osvm_out=pd.read_csv('osvm_out.csv')\n",
    "osvm_ot=pd.read_csv('osvm_ot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f832c9d",
   "metadata": {
    "id": "1f832c9d"
   },
   "outputs": [],
   "source": [
    "lof_out=lof_out.to_numpy()\n",
    "lof_ot=lof_ot.to_numpy()\n",
    "\n",
    "isf_out=isf_out.to_numpy()\n",
    "isf_ot=isf_ot.to_numpy()\n",
    "\n",
    "ee_out=ee_out.to_numpy()\n",
    "ee_ot=ee_ot.to_numpy()\n",
    "\n",
    "osvm_out=osvm_out.to_numpy()\n",
    "osvm_ot=osvm_ot.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c22fe379",
   "metadata": {
    "id": "c22fe379"
   },
   "outputs": [],
   "source": [
    "sampling_res=pd.DataFrame(columns=['name','Train shape','normal percent','fraud percent','accuracy','precision','recall','f1-score','tn', 'fp', 'fn', 'tp'])\n",
    "sampling_c=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c464c8dc",
   "metadata": {
    "id": "c464c8dc"
   },
   "outputs": [],
   "source": [
    "def generator(z, reuse=None):\n",
    "    with tf.variable_scope(\"gen\", reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=z, units=128)\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1, hidden1)\n",
    "        hidden2 = tf.layers.dense(inputs=hidden1, units=64)\n",
    "        hidden2 = tf.maximum(alpha*hidden2, hidden2)\n",
    "        output = tf.layers.dense(hidden2, units=18, activation=tf.nn.tanh)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ef24da4",
   "metadata": {
    "id": "9ef24da4"
   },
   "outputs": [],
   "source": [
    "def discriminator(X, reuse=None):\n",
    "    with tf.variable_scope(\"dis\", reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=X, units=128)\n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1, hidden1)\n",
    "        hidden2 = tf.layers.dense(inputs=hidden1, units=128)\n",
    "        hidden2 = tf.maximum(alpha*hidden2, hidden2)\n",
    "        logits = tf.layers.dense(hidden2, units=1)\n",
    "        output = tf.sigmoid(logits)\n",
    "        return output, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29e13f40",
   "metadata": {
    "id": "29e13f40"
   },
   "outputs": [],
   "source": [
    "real_data = tf.placeholder(tf.float32, shape=[None, 18])\n",
    "z = tf.placeholder(tf.float32, shape=[None, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6e4bd45",
   "metadata": {
    "id": "e6e4bd45"
   },
   "outputs": [],
   "source": [
    "G = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc2f592c",
   "metadata": {
    "id": "cc2f592c"
   },
   "outputs": [],
   "source": [
    "D_output_real, D_logits_real = discriminator(real_data)\n",
    "D_output_fake, D_logits_fake  = discriminator(G, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e793ed65",
   "metadata": {
    "id": "e793ed65"
   },
   "outputs": [],
   "source": [
    "# LOSS\n",
    "def loss_func(logits_in, labels_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits_in, labels=labels_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61dc4299",
   "metadata": {
    "id": "61dc4299"
   },
   "outputs": [],
   "source": [
    "D_real_loss = loss_func(D_logits_real, tf.ones_like(D_logits_real)*0.9)\n",
    "D_fake_loss = loss_func(D_logits_fake, tf.zeros_like(D_logits_real))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e45b66f2",
   "metadata": {
    "id": "e45b66f2"
   },
   "outputs": [],
   "source": [
    "D_loss = D_real_loss + D_fake_loss\n",
    "G_loss = loss_func(D_logits_fake, tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff0ef9ca",
   "metadata": {
    "id": "ff0ef9ca"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name]\n",
    "g_vars = [var for var in tvars if 'gen' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46f1d3b4",
   "metadata": {
    "id": "46f1d3b4"
   },
   "outputs": [],
   "source": [
    "D_trainer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(D_loss, var_list=d_vars)\n",
    "G_trainer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb214a2b",
   "metadata": {
    "id": "fb214a2b"
   },
   "outputs": [],
   "source": [
    "def next_batch(num, data):\n",
    "    '''\n",
    "    Return a total of `num` random samples. \n",
    "    '''\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    data_shuffle = [data.iloc[i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbc3e76a",
   "metadata": {
    "id": "bbc3e76a"
   },
   "outputs": [],
   "source": [
    "# def resmaker1(name,X_resampled, y_resampled,sampling_c,X_test,y_test):\n",
    "#     RF = RandomForestClassifier()\n",
    "#     RF.fit(X_resampled, y_resampled)\n",
    "#     preds = RF.predict(X_test)\n",
    "#     y_resampled=y_resampled.reshape(-1,)\n",
    "#     y_resampled = pd.Series(y_resampled)\n",
    "#     classes=y_resampled.value_counts()\n",
    "#     normal_share=round(classes[0]/y_resampled.count()*100,2)\n",
    "#     fraud_share=round(classes[1]/y_resampled.count()*100, 2)\n",
    "#     R=classification_report(y_test, preds,output_dict=True)\n",
    "#     sampling_res.loc[sampling_c]=[name,X_resampled.shape,normal_share,fraud_share,R['accuracy'],R['macro avg']['precision'],R['macro avg']['recall'],R['macro avg']['f1-score']]\n",
    "#     sampling_c+=1\n",
    "#     return sampling_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bacef1a9",
   "metadata": {
    "id": "bacef1a9"
   },
   "outputs": [],
   "source": [
    "k=296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b483485",
   "metadata": {
    "id": "7b483485"
   },
   "outputs": [],
   "source": [
    "def resmaker1(k,name,X_resampled, y_resampled,sampling_c,X_test,y_test):\n",
    "#     RF = RandomForestClassifier()\n",
    "#     RF.fit(X_resampled, y_resampled)\n",
    "#     preds = RF.predict(X_test)\n",
    "#     classes=y_resampled.value_counts()\n",
    "#     normal_share=round(classes[0]/y_resampled.count()*100,2)\n",
    "#     fraud_share=round(classes[1]/y_resampled.count()*100, 2)\n",
    "#     R=classification_report(y_test, preds,output_dict=True)\n",
    "#     tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "#     sampling_res.loc[sampling_c]=[name,X_resampled.shape,normal_share.Class,fraud_share.Class,R['accuracy'],R['macro avg']['precision'],R['macro avg']['recall'],R['macro avg']['f1-score'],tn, fp, fn, tp]\n",
    "#     sampling_c+=1\n",
    "#     return sampling_c\n",
    "    xdfname=' X_resampled '+' + '+name+'.csv'\n",
    "    ydfname=' y_resampled '+' + '+name+'.csv'\n",
    "    X_resampled.to_csv(str(k)+xdfname,index=False)\n",
    "    y_resampled.to_csv(str(k)+ydfname,index=False)\n",
    "    X_test.to_csv(str(k)+' test '+xdfname,index=False)\n",
    "    y_test.to_csv(str(k)+' test '+ydfname,index=False)\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "338474e6",
   "metadata": {
    "id": "338474e6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def GAN(X_train,y_train,no_of_samples_to_generate):\n",
    "    X_ones = X_train[y_train.Class == 1]\n",
    "    X_ones.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    batch_size = 10\n",
    "    epochs = 5000\n",
    "    init = tf.global_variables_initializer()\n",
    "    samples = []\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            num_batches = len(X_ones) // batch_size\n",
    "            for i in range(num_batches):\n",
    "\n",
    "                batch_X = next_batch(batch_size, X_ones)            \n",
    "                batch_z = np.random.uniform(-1,1, size=(batch_size,100))\n",
    "\n",
    "                _ = sess.run(D_trainer, feed_dict={real_data:batch_X, z: batch_z})\n",
    "                _ = sess.run(G_trainer, feed_dict={z: batch_z})         \n",
    "\n",
    "        sample_z = np.random.uniform(-1,1,size=(no_of_samples_to_generate, 100)) # new samples will be generated\n",
    "        gen_sample = sess.run(generator(z, reuse=True), feed_dict={z:sample_z})\n",
    "        samples.append(gen_sample)\n",
    "    X_fake = pd.DataFrame(samples[0], columns=df1.columns)\n",
    "    X_augmented_data = np.append(X_train, np.array(X_fake), axis=0)\n",
    "    y_fake = np.ones(no_of_samples_to_generate)\n",
    "    y_fake=y_fake.reshape(-1,1)\n",
    "    y_augmented_data = np.append(y_train, y_fake, axis=0)\n",
    "    return X_augmented_data,y_augmented_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8ea357b",
   "metadata": {
    "id": "f8ea357b"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df1, Target, test_size = 0.3,random_state=0)\n",
    "for i in [10129,21768,24542,39458,49409,66014,99164,198674]:\n",
    "    X_resampled, y_resampled = GAN(X_train,y_train,no_of_samples_to_generate=i)\n",
    "    X_resampled = pd.DataFrame (X_resampled,columns =X_train.columns)\n",
    "    y_resampled = pd.DataFrame (y_resampled,columns =y_train.columns)\n",
    "    sampling_c=resmaker1(k,'Gan',X_resampled, y_resampled,sampling_c,X_test,y_test)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cf916cc6",
   "metadata": {
    "id": "cf916cc6",
    "outputId": "d6551944-bbcc-4a71-95b1-c80d8304c8fd"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(lof_res, lof_t, test_size = 0.3,random_state=0)\n",
    "for i in [10129,21768,24542,39458,49409,66014,99164,198674]:\n",
    "    X_resampled, y_resampled = GAN(X_train,y_train,no_of_samples_to_generate=i)\n",
    "    X_resampled=np.concatenate((lof_out, X_resampled), axis=0)\n",
    "    y_resampled=np.concatenate((lof_ot, y_resampled), axis=0)\n",
    "    y_resampled[y_resampled==-1]=1\n",
    "    X_resampled = pd.DataFrame (X_resampled,columns =X_train.columns)\n",
    "    y_resampled = pd.DataFrame (y_resampled,columns =y_train.columns)\n",
    "    sampling_c=resmaker1(k,'Gan + lof',X_resampled, y_resampled,sampling_c,X_test,y_test)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e43be1c1",
   "metadata": {
    "id": "e43be1c1"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(isf_res, isf_t, test_size = 0.3,random_state=0)\n",
    "for i in [10129,21768,24542,39458,49409,66014,99164,198674]:\n",
    "    X_resampled, y_resampled = GAN(X_train,y_train,no_of_samples_to_generate=i)\n",
    "    X_resampled=np.concatenate((isf_out, X_resampled), axis=0)\n",
    "    y_resampled=np.concatenate((isf_ot, y_resampled), axis=0)\n",
    "    y_resampled[y_resampled==-1]=1\n",
    "    X_resampled = pd.DataFrame (X_resampled,columns =X_train.columns)\n",
    "    y_resampled = pd.DataFrame (y_resampled,columns =y_train.columns)\n",
    "    sampling_c=resmaker1(k,'Gan + isf',X_resampled, y_resampled,sampling_c,X_test,y_test)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "81323f6c",
   "metadata": {
    "id": "81323f6c"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ee_res, ee_t, test_size = 0.3,random_state=0)\n",
    "for i in [10129,21768,24542,39458,49409,66014,99164,198674]:\n",
    "    X_resampled, y_resampled = GAN(X_train,y_train,no_of_samples_to_generate=i)\n",
    "    X_resampled=np.concatenate((ee_out, X_resampled), axis=0)\n",
    "    y_resampled=np.concatenate((ee_ot, y_resampled), axis=0)\n",
    "    y_resampled[y_resampled==-1]=1\n",
    "    X_resampled = pd.DataFrame (X_resampled,columns =X_train.columns)\n",
    "    y_resampled = pd.DataFrame (y_resampled,columns =y_train.columns)\n",
    "    sampling_c=resmaker1(k,'Gan + EllipticEnvelope',X_resampled, y_resampled,sampling_c,X_test,y_test)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbd0ab9b",
   "metadata": {
    "id": "fbd0ab9b"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(osvm_res, osvm_t, test_size = 0.3,random_state=0)\n",
    "for i in [10129,21768,24542,39458,49409,66014,99164,198674]:\n",
    "    X_resampled, y_resampled = GAN(X_train,y_train,no_of_samples_to_generate=i)\n",
    "    X_resampled=np.concatenate((osvm_out, X_resampled), axis=0)\n",
    "    y_resampled=np.concatenate((osvm_ot, y_resampled), axis=0)\n",
    "    y_resampled[y_resampled==-1]=1\n",
    "    X_resampled = pd.DataFrame (X_resampled,columns =X_train.columns)\n",
    "    y_resampled = pd.DataFrame (y_resampled,columns =y_train.columns)\n",
    "    sampling_c=resmaker1(k,'Gan + ocsvm',X_resampled, y_resampled,sampling_c,X_test,y_test)\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd267c46",
   "metadata": {
    "id": "fd267c46"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "gan_creditcard_v3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
