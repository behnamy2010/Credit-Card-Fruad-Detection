{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "avMXTLc-ezfE"
   },
   "source": [
    "## Credit Card Fraud Detection using CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "hEndev1uezfb",
    "outputId": "2899e28d-8366-4682-87bc-9946645bc246"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zJap58-Zezfc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import  seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GPu4zSP5ezfd",
    "outputId": "f483138c-8841-4170-e3d6-57c133cadd00"
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('brazilian credit card.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "b8rFM-jZezff",
    "outputId": "962fac87-ef75-431c-d86f-cefa858fcc24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374823, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I8BWtkOpezfg",
    "outputId": "0fbb0afe-b17f-4b8a-cc43-3faf6f151b81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mcc_cat numeric                0\n",
       "mcc_ant_cat numeric            0\n",
       "cep_cat numeric                0\n",
       "cep_ant_cat numeric            0\n",
       "valor_trans_cat numeric        0\n",
       "valor_trans_ant_cat numeric    0\n",
       "pos_entry numeric              0\n",
       "lim_cred_cat numeric           0\n",
       "bandeira_cat numeric           0\n",
       "variante_cat numeric           0\n",
       "score_cat numeric              0\n",
       "tp_pessoa_cat numeric          0\n",
       "trans_nacional_cat numeric     0\n",
       "qtde_parc_cat numeric          0\n",
       "velocidade_cat numeric         0\n",
       "dif_score_cat numeric          0\n",
       "trans_limit_cat numeric        0\n",
       "Class                          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DmImZcdXezfh",
    "outputId": "ada6fd18-7456-4694-eb35-df0eaf6a64c2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 374823 entries, 0 to 374822\n",
      "Data columns (total 18 columns):\n",
      " #   Column                       Non-Null Count   Dtype\n",
      "---  ------                       --------------   -----\n",
      " 0   mcc_cat numeric              374823 non-null  int64\n",
      " 1   mcc_ant_cat numeric          374823 non-null  int64\n",
      " 2   cep_cat numeric              374823 non-null  int64\n",
      " 3   cep_ant_cat numeric          374823 non-null  int64\n",
      " 4   valor_trans_cat numeric      374823 non-null  int64\n",
      " 5   valor_trans_ant_cat numeric  374823 non-null  int64\n",
      " 6   pos_entry numeric            374823 non-null  int64\n",
      " 7   lim_cred_cat numeric         374823 non-null  int64\n",
      " 8   bandeira_cat numeric         374823 non-null  int64\n",
      " 9   variante_cat numeric         374823 non-null  int64\n",
      " 10  score_cat numeric            374823 non-null  int64\n",
      " 11  tp_pessoa_cat numeric        374823 non-null  int64\n",
      " 12  trans_nacional_cat numeric   374823 non-null  int64\n",
      " 13  qtde_parc_cat numeric        374823 non-null  int64\n",
      " 14  velocidade_cat numeric       374823 non-null  int64\n",
      " 15  dif_score_cat numeric        374823 non-null  int64\n",
      " 16  trans_limit_cat numeric      374823 non-null  int64\n",
      " 17  Class                        374823 non-null  int64\n",
      "dtypes: int64(18)\n",
      "memory usage: 51.5 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "6BKfpbItezfj",
    "outputId": "15081b30-92e3-4f66-a15f-31b3458ce552"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    360792\n",
       "1     14031\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "70l_gbSXezfr"
   },
   "outputs": [],
   "source": [
    "X = data.drop('Class', axis = 1)\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "F0aDV9Jaezfs"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "yvOmdXLrezft",
    "outputId": "aa7599c3-d86c-4284-94d9-2e5bc29313fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((299858, 17), (74965, 17))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "JYUnnamDezfu"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "RuBH9eJNezfv"
   },
   "outputs": [],
   "source": [
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vHKENMjcezf3",
    "outputId": "874478b4-d028-45b4-ae26-8cea6364b440"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299858, 17)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HgHFgdyvezf3"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "rgKEVMzMezf4",
    "outputId": "17b9b5db-fed0-4214-f105-4b6a5281de6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((299858, 17, 1), (74965, 17, 1))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6mD15LV7ezf5"
   },
   "source": [
    "### Build CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "TVeUNsApezf5"
   },
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "model = Sequential()\n",
    "model.add(Conv1D(32, 2, activation='relu', input_shape = X_train[0].shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv1D(64, 2, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "9cOwOrbJezf6",
    "outputId": "b19ad3bc-341c-48ac-93c9-03af409babc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 16, 32)            96        \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 16, 32)           128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 32)            0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 15, 64)            4160      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 15, 64)           256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 15, 64)            0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 960)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                61504     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,209\n",
      "Trainable params: 66,017\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "qKH9-n0aezf6"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics=['accuracy','Precision','Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "SGdyWIzvezf6",
    "outputId": "18004961-2fc8-4953-fae6-0326455b5d82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "600/600 [==============================] - 32s 46ms/step - loss: 0.1436 - accuracy: 0.9581 - precision: 0.2394 - recall: 0.0551 - val_loss: 0.1101 - val_accuracy: 0.9626 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/500\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 0.1177 - accuracy: 0.9625 - precision: 0.4530 - recall: 0.0142 - val_loss: 0.1048 - val_accuracy: 0.9628 - val_precision: 0.8571 - val_recall: 0.0064\n",
      "Epoch 3/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.1138 - accuracy: 0.9628 - precision: 0.5551 - recall: 0.0350 - val_loss: 0.1032 - val_accuracy: 0.9631 - val_precision: 0.9111 - val_recall: 0.0146\n",
      "Epoch 4/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.1104 - accuracy: 0.9628 - precision: 0.5291 - recall: 0.0462 - val_loss: 0.1010 - val_accuracy: 0.9630 - val_precision: 0.8723 - val_recall: 0.0146\n",
      "Epoch 5/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.1086 - accuracy: 0.9630 - precision: 0.5447 - recall: 0.0683 - val_loss: 0.0989 - val_accuracy: 0.9632 - val_precision: 0.8400 - val_recall: 0.0225\n",
      "Epoch 6/500\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 0.1066 - accuracy: 0.9636 - precision: 0.5813 - recall: 0.0955 - val_loss: 0.0970 - val_accuracy: 0.9638 - val_precision: 0.9245 - val_recall: 0.0349\n",
      "Epoch 7/500\n",
      "600/600 [==============================] - 22s 36ms/step - loss: 0.1049 - accuracy: 0.9641 - precision: 0.6145 - recall: 0.1095 - val_loss: 0.0948 - val_accuracy: 0.9644 - val_precision: 0.8497 - val_recall: 0.0584\n",
      "Epoch 8/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.1034 - accuracy: 0.9644 - precision: 0.6111 - recall: 0.1326 - val_loss: 0.0927 - val_accuracy: 0.9651 - val_precision: 0.8357 - val_recall: 0.0834\n",
      "Epoch 9/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.1025 - accuracy: 0.9647 - precision: 0.6277 - recall: 0.1375 - val_loss: 0.0911 - val_accuracy: 0.9654 - val_precision: 0.9057 - val_recall: 0.0855\n",
      "Epoch 10/500\n",
      "600/600 [==============================] - 40s 67ms/step - loss: 0.1010 - accuracy: 0.9647 - precision: 0.6256 - recall: 0.1453 - val_loss: 0.0892 - val_accuracy: 0.9672 - val_precision: 0.7267 - val_recall: 0.1999\n",
      "Epoch 11/500\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0998 - accuracy: 0.9654 - precision: 0.6485 - recall: 0.1657 - val_loss: 0.0886 - val_accuracy: 0.9657 - val_precision: 0.8719 - val_recall: 0.0994\n",
      "Epoch 12/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0987 - accuracy: 0.9656 - precision: 0.6549 - recall: 0.1731 - val_loss: 0.0863 - val_accuracy: 0.9673 - val_precision: 0.8284 - val_recall: 0.1582\n",
      "Epoch 13/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0974 - accuracy: 0.9659 - precision: 0.6593 - recall: 0.1819 - val_loss: 0.0845 - val_accuracy: 0.9675 - val_precision: 0.8755 - val_recall: 0.1529\n",
      "Epoch 14/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0965 - accuracy: 0.9662 - precision: 0.6669 - recall: 0.1958 - val_loss: 0.0821 - val_accuracy: 0.9692 - val_precision: 0.8250 - val_recall: 0.2234\n",
      "Epoch 15/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0956 - accuracy: 0.9666 - precision: 0.6753 - recall: 0.2086 - val_loss: 0.0823 - val_accuracy: 0.9689 - val_precision: 0.8420 - val_recall: 0.2088\n",
      "Epoch 16/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0951 - accuracy: 0.9667 - precision: 0.6748 - recall: 0.2135 - val_loss: 0.0817 - val_accuracy: 0.9681 - val_precision: 0.9014 - val_recall: 0.1661\n",
      "Epoch 17/500\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 0.0940 - accuracy: 0.9670 - precision: 0.6806 - recall: 0.2212 - val_loss: 0.0786 - val_accuracy: 0.9697 - val_precision: 0.8789 - val_recall: 0.2199\n",
      "Epoch 18/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0938 - accuracy: 0.9670 - precision: 0.6778 - recall: 0.2247 - val_loss: 0.0787 - val_accuracy: 0.9691 - val_precision: 0.8824 - val_recall: 0.2006\n",
      "Epoch 19/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0926 - accuracy: 0.9677 - precision: 0.7023 - recall: 0.2391 - val_loss: 0.0770 - val_accuracy: 0.9698 - val_precision: 0.9115 - val_recall: 0.2128\n",
      "Epoch 20/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0917 - accuracy: 0.9677 - precision: 0.7003 - recall: 0.2383 - val_loss: 0.0765 - val_accuracy: 0.9703 - val_precision: 0.8638 - val_recall: 0.2441\n",
      "Epoch 21/500\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 0.0907 - accuracy: 0.9679 - precision: 0.6974 - recall: 0.2496 - val_loss: 0.0747 - val_accuracy: 0.9710 - val_precision: 0.9171 - val_recall: 0.2484\n",
      "Epoch 22/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0906 - accuracy: 0.9682 - precision: 0.7065 - recall: 0.2557 - val_loss: 0.0736 - val_accuracy: 0.9718 - val_precision: 0.8460 - val_recall: 0.3015\n",
      "Epoch 23/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0896 - accuracy: 0.9682 - precision: 0.7067 - recall: 0.2587 - val_loss: 0.0730 - val_accuracy: 0.9721 - val_precision: 0.9191 - val_recall: 0.2794\n",
      "Epoch 24/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0896 - accuracy: 0.9682 - precision: 0.7078 - recall: 0.2564 - val_loss: 0.0713 - val_accuracy: 0.9720 - val_precision: 0.8801 - val_recall: 0.2904\n",
      "Epoch 25/500\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 0.0886 - accuracy: 0.9685 - precision: 0.7123 - recall: 0.2663 - val_loss: 0.0708 - val_accuracy: 0.9727 - val_precision: 0.9417 - val_recall: 0.2876\n",
      "Epoch 26/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0885 - accuracy: 0.9686 - precision: 0.7138 - recall: 0.2682 - val_loss: 0.0704 - val_accuracy: 0.9731 - val_precision: 0.9368 - val_recall: 0.3011\n",
      "Epoch 27/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0880 - accuracy: 0.9686 - precision: 0.7148 - recall: 0.2704 - val_loss: 0.0694 - val_accuracy: 0.9737 - val_precision: 0.9257 - val_recall: 0.3239\n",
      "Epoch 28/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0878 - accuracy: 0.9692 - precision: 0.7244 - recall: 0.2845 - val_loss: 0.0690 - val_accuracy: 0.9745 - val_precision: 0.8996 - val_recall: 0.3574\n",
      "Epoch 29/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0875 - accuracy: 0.9690 - precision: 0.7246 - recall: 0.2791 - val_loss: 0.0684 - val_accuracy: 0.9743 - val_precision: 0.9324 - val_recall: 0.3393\n",
      "Epoch 30/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0871 - accuracy: 0.9691 - precision: 0.7197 - recall: 0.2845 - val_loss: 0.0691 - val_accuracy: 0.9729 - val_precision: 0.9206 - val_recall: 0.3015\n",
      "Epoch 31/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0868 - accuracy: 0.9694 - precision: 0.7336 - recall: 0.2876 - val_loss: 0.0656 - val_accuracy: 0.9757 - val_precision: 0.9307 - val_recall: 0.3781\n",
      "Epoch 32/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0856 - accuracy: 0.9694 - precision: 0.7301 - recall: 0.2889 - val_loss: 0.0662 - val_accuracy: 0.9751 - val_precision: 0.9202 - val_recall: 0.3656\n",
      "Epoch 33/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0855 - accuracy: 0.9698 - precision: 0.7375 - recall: 0.2996 - val_loss: 0.0656 - val_accuracy: 0.9749 - val_precision: 0.9053 - val_recall: 0.3681\n",
      "Epoch 34/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0858 - accuracy: 0.9697 - precision: 0.7377 - recall: 0.2957 - val_loss: 0.0648 - val_accuracy: 0.9747 - val_precision: 0.9376 - val_recall: 0.3482\n",
      "Epoch 35/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0854 - accuracy: 0.9697 - precision: 0.7353 - recall: 0.2979 - val_loss: 0.0658 - val_accuracy: 0.9753 - val_precision: 0.9350 - val_recall: 0.3642\n",
      "Epoch 36/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0847 - accuracy: 0.9697 - precision: 0.7336 - recall: 0.2992 - val_loss: 0.0646 - val_accuracy: 0.9760 - val_precision: 0.9514 - val_recall: 0.3770\n",
      "Epoch 37/500\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 0.0842 - accuracy: 0.9697 - precision: 0.7314 - recall: 0.3015 - val_loss: 0.0623 - val_accuracy: 0.9763 - val_precision: 0.9408 - val_recall: 0.3909\n",
      "Epoch 38/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0845 - accuracy: 0.9698 - precision: 0.7293 - recall: 0.3062 - val_loss: 0.0628 - val_accuracy: 0.9760 - val_precision: 0.9524 - val_recall: 0.3781\n",
      "Epoch 39/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0836 - accuracy: 0.9702 - precision: 0.7446 - recall: 0.3104 - val_loss: 0.0634 - val_accuracy: 0.9761 - val_precision: 0.9650 - val_recall: 0.3738\n",
      "Epoch 40/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0831 - accuracy: 0.9701 - precision: 0.7410 - recall: 0.3098 - val_loss: 0.0614 - val_accuracy: 0.9770 - val_precision: 0.9362 - val_recall: 0.4134\n",
      "Epoch 41/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0831 - accuracy: 0.9702 - precision: 0.7445 - recall: 0.3115 - val_loss: 0.0614 - val_accuracy: 0.9753 - val_precision: 0.9450 - val_recall: 0.3610\n",
      "Epoch 42/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0824 - accuracy: 0.9706 - precision: 0.7485 - recall: 0.3234 - val_loss: 0.0612 - val_accuracy: 0.9768 - val_precision: 0.9242 - val_recall: 0.4130\n",
      "Epoch 43/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0826 - accuracy: 0.9705 - precision: 0.7473 - recall: 0.3185 - val_loss: 0.0599 - val_accuracy: 0.9772 - val_precision: 0.9344 - val_recall: 0.4216\n",
      "Epoch 44/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0820 - accuracy: 0.9706 - precision: 0.7506 - recall: 0.3234 - val_loss: 0.0609 - val_accuracy: 0.9761 - val_precision: 0.9478 - val_recall: 0.3817\n",
      "Epoch 45/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0825 - accuracy: 0.9707 - precision: 0.7529 - recall: 0.3228 - val_loss: 0.0590 - val_accuracy: 0.9771 - val_precision: 0.9226 - val_recall: 0.4248\n",
      "Epoch 46/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0808 - accuracy: 0.9711 - precision: 0.7560 - recall: 0.3356 - val_loss: 0.0583 - val_accuracy: 0.9779 - val_precision: 0.9272 - val_recall: 0.4448\n",
      "Epoch 47/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0815 - accuracy: 0.9709 - precision: 0.7530 - recall: 0.3316 - val_loss: 0.0590 - val_accuracy: 0.9780 - val_precision: 0.9446 - val_recall: 0.4376\n",
      "Epoch 48/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0818 - accuracy: 0.9708 - precision: 0.7577 - recall: 0.3229 - val_loss: 0.0595 - val_accuracy: 0.9771 - val_precision: 0.9359 - val_recall: 0.4166\n",
      "Epoch 49/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0818 - accuracy: 0.9707 - precision: 0.7503 - recall: 0.3253 - val_loss: 0.0594 - val_accuracy: 0.9767 - val_precision: 0.9640 - val_recall: 0.3917\n",
      "Epoch 50/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0813 - accuracy: 0.9709 - precision: 0.7501 - recall: 0.3357 - val_loss: 0.0569 - val_accuracy: 0.9784 - val_precision: 0.9342 - val_recall: 0.4551\n",
      "Epoch 51/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0804 - accuracy: 0.9710 - precision: 0.7519 - recall: 0.3357 - val_loss: 0.0567 - val_accuracy: 0.9787 - val_precision: 0.9248 - val_recall: 0.4690\n",
      "Epoch 52/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0805 - accuracy: 0.9710 - precision: 0.7560 - recall: 0.3343 - val_loss: 0.0568 - val_accuracy: 0.9790 - val_precision: 0.9625 - val_recall: 0.4569\n",
      "Epoch 53/500\n",
      "600/600 [==============================] - 22s 37ms/step - loss: 0.0807 - accuracy: 0.9712 - precision: 0.7605 - recall: 0.3359 - val_loss: 0.0561 - val_accuracy: 0.9790 - val_precision: 0.9535 - val_recall: 0.4601\n",
      "Epoch 54/500\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 0.0805 - accuracy: 0.9713 - precision: 0.7618 - recall: 0.3388 - val_loss: 0.0577 - val_accuracy: 0.9775 - val_precision: 0.9644 - val_recall: 0.4148\n",
      "Epoch 55/500\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 0.0803 - accuracy: 0.9714 - precision: 0.7626 - recall: 0.3437 - val_loss: 0.0565 - val_accuracy: 0.9781 - val_precision: 0.9598 - val_recall: 0.4341\n",
      "Epoch 56/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0799 - accuracy: 0.9714 - precision: 0.7686 - recall: 0.3382 - val_loss: 0.0557 - val_accuracy: 0.9783 - val_precision: 0.9482 - val_recall: 0.4433\n",
      "Epoch 57/500\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 0.0791 - accuracy: 0.9714 - precision: 0.7618 - recall: 0.3449 - val_loss: 0.0547 - val_accuracy: 0.9796 - val_precision: 0.9236 - val_recall: 0.4957\n",
      "Epoch 58/500\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 0.0802 - accuracy: 0.9714 - precision: 0.7546 - recall: 0.3498 - val_loss: 0.0584 - val_accuracy: 0.9764 - val_precision: 0.9824 - val_recall: 0.3774\n",
      "Epoch 59/500\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 0.0797 - accuracy: 0.9711 - precision: 0.7608 - recall: 0.3344 - val_loss: 0.0555 - val_accuracy: 0.9785 - val_precision: 0.9482 - val_recall: 0.4505\n",
      "Epoch 60/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0790 - accuracy: 0.9715 - precision: 0.7616 - recall: 0.3482 - val_loss: 0.0552 - val_accuracy: 0.9784 - val_precision: 0.9633 - val_recall: 0.4401\n",
      "Epoch 61/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0797 - accuracy: 0.9714 - precision: 0.7648 - recall: 0.3421 - val_loss: 0.0556 - val_accuracy: 0.9785 - val_precision: 0.9515 - val_recall: 0.4476\n",
      "Epoch 62/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0786 - accuracy: 0.9718 - precision: 0.7681 - recall: 0.3532 - val_loss: 0.0534 - val_accuracy: 0.9795 - val_precision: 0.9511 - val_recall: 0.4779\n",
      "Epoch 63/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0790 - accuracy: 0.9717 - precision: 0.7658 - recall: 0.3519 - val_loss: 0.0547 - val_accuracy: 0.9784 - val_precision: 0.9782 - val_recall: 0.4323\n",
      "Epoch 64/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0780 - accuracy: 0.9722 - precision: 0.7719 - recall: 0.3641 - val_loss: 0.0551 - val_accuracy: 0.9784 - val_precision: 0.9473 - val_recall: 0.4487\n",
      "Epoch 65/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0784 - accuracy: 0.9715 - precision: 0.7592 - recall: 0.3494 - val_loss: 0.0538 - val_accuracy: 0.9796 - val_precision: 0.9467 - val_recall: 0.4808\n",
      "Epoch 66/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0781 - accuracy: 0.9716 - precision: 0.7629 - recall: 0.3516 - val_loss: 0.0539 - val_accuracy: 0.9784 - val_precision: 0.9541 - val_recall: 0.4448\n",
      "Epoch 67/500\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 0.0785 - accuracy: 0.9716 - precision: 0.7585 - recall: 0.3555 - val_loss: 0.0539 - val_accuracy: 0.9789 - val_precision: 0.9650 - val_recall: 0.4522\n",
      "Epoch 68/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0779 - accuracy: 0.9720 - precision: 0.7690 - recall: 0.3591 - val_loss: 0.0541 - val_accuracy: 0.9791 - val_precision: 0.9545 - val_recall: 0.4640\n",
      "Epoch 69/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0785 - accuracy: 0.9716 - precision: 0.7650 - recall: 0.3480 - val_loss: 0.0537 - val_accuracy: 0.9792 - val_precision: 0.9656 - val_recall: 0.4601\n",
      "Epoch 70/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0783 - accuracy: 0.9719 - precision: 0.7675 - recall: 0.3590 - val_loss: 0.0547 - val_accuracy: 0.9791 - val_precision: 0.9572 - val_recall: 0.4622\n",
      "Epoch 71/500\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 0.0774 - accuracy: 0.9720 - precision: 0.7669 - recall: 0.3604 - val_loss: 0.0538 - val_accuracy: 0.9795 - val_precision: 0.9422 - val_recall: 0.4822\n",
      "Epoch 72/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0770 - accuracy: 0.9719 - precision: 0.7626 - recall: 0.3612 - val_loss: 0.0527 - val_accuracy: 0.9799 - val_precision: 0.9435 - val_recall: 0.4936\n",
      "Epoch 73/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0781 - accuracy: 0.9717 - precision: 0.7614 - recall: 0.3573 - val_loss: 0.0534 - val_accuracy: 0.9792 - val_precision: 0.9534 - val_recall: 0.4661\n",
      "Epoch 74/500\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 0.0771 - accuracy: 0.9724 - precision: 0.7741 - recall: 0.3700 - val_loss: 0.0525 - val_accuracy: 0.9799 - val_precision: 0.9398 - val_recall: 0.4954\n",
      "Epoch 75/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0770 - accuracy: 0.9721 - precision: 0.7686 - recall: 0.3657 - val_loss: 0.0514 - val_accuracy: 0.9802 - val_precision: 0.9473 - val_recall: 0.4996\n",
      "Epoch 76/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0772 - accuracy: 0.9722 - precision: 0.7668 - recall: 0.3696 - val_loss: 0.0528 - val_accuracy: 0.9787 - val_precision: 0.9682 - val_recall: 0.4448\n",
      "Epoch 77/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0770 - accuracy: 0.9719 - precision: 0.7666 - recall: 0.3599 - val_loss: 0.0508 - val_accuracy: 0.9806 - val_precision: 0.9339 - val_recall: 0.5189\n",
      "Epoch 78/500\n",
      "600/600 [==============================] - 23s 38ms/step - loss: 0.0772 - accuracy: 0.9719 - precision: 0.7660 - recall: 0.3594 - val_loss: 0.0519 - val_accuracy: 0.9799 - val_precision: 0.9494 - val_recall: 0.4882\n",
      "Epoch 79/500\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 0.0773 - accuracy: 0.9720 - precision: 0.7696 - recall: 0.3612 - val_loss: 0.0522 - val_accuracy: 0.9806 - val_precision: 0.9617 - val_recall: 0.5014\n",
      "Epoch 80/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0771 - accuracy: 0.9717 - precision: 0.7616 - recall: 0.3549 - val_loss: 0.0518 - val_accuracy: 0.9799 - val_precision: 0.9616 - val_recall: 0.4822\n",
      "Epoch 81/500\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 0.0770 - accuracy: 0.9721 - precision: 0.7666 - recall: 0.3675 - val_loss: 0.0518 - val_accuracy: 0.9797 - val_precision: 0.9742 - val_recall: 0.4711\n",
      "Epoch 82/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0764 - accuracy: 0.9722 - precision: 0.7684 - recall: 0.3686 - val_loss: 0.0509 - val_accuracy: 0.9798 - val_precision: 0.9486 - val_recall: 0.4872\n",
      "Epoch 83/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0770 - accuracy: 0.9719 - precision: 0.7632 - recall: 0.3607 - val_loss: 0.0507 - val_accuracy: 0.9813 - val_precision: 0.9478 - val_recall: 0.5303\n",
      "Epoch 84/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0761 - accuracy: 0.9725 - precision: 0.7702 - recall: 0.3775 - val_loss: 0.0518 - val_accuracy: 0.9804 - val_precision: 0.9478 - val_recall: 0.5043\n",
      "Epoch 85/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0767 - accuracy: 0.9722 - precision: 0.7734 - recall: 0.3652 - val_loss: 0.0515 - val_accuracy: 0.9808 - val_precision: 0.9489 - val_recall: 0.5160\n",
      "Epoch 86/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0752 - accuracy: 0.9726 - precision: 0.7729 - recall: 0.3804 - val_loss: 0.0496 - val_accuracy: 0.9816 - val_precision: 0.9497 - val_recall: 0.5381\n",
      "Epoch 87/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0761 - accuracy: 0.9726 - precision: 0.7756 - recall: 0.3771 - val_loss: 0.0497 - val_accuracy: 0.9810 - val_precision: 0.9587 - val_recall: 0.5132\n",
      "Epoch 88/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0761 - accuracy: 0.9723 - precision: 0.7715 - recall: 0.3679 - val_loss: 0.0504 - val_accuracy: 0.9803 - val_precision: 0.9438 - val_recall: 0.5025\n",
      "Epoch 89/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0749 - accuracy: 0.9729 - precision: 0.7818 - recall: 0.3836 - val_loss: 0.0509 - val_accuracy: 0.9803 - val_precision: 0.9506 - val_recall: 0.5007\n",
      "Epoch 90/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0761 - accuracy: 0.9726 - precision: 0.7796 - recall: 0.3730 - val_loss: 0.0508 - val_accuracy: 0.9796 - val_precision: 0.9571 - val_recall: 0.4768\n",
      "Epoch 91/500\n",
      "600/600 [==============================] - 33s 54ms/step - loss: 0.0753 - accuracy: 0.9726 - precision: 0.7733 - recall: 0.3790 - val_loss: 0.0510 - val_accuracy: 0.9806 - val_precision: 0.9556 - val_recall: 0.5057\n",
      "Epoch 92/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0759 - accuracy: 0.9725 - precision: 0.7759 - recall: 0.3724 - val_loss: 0.0501 - val_accuracy: 0.9805 - val_precision: 0.9661 - val_recall: 0.4971\n",
      "Epoch 93/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0754 - accuracy: 0.9726 - precision: 0.7788 - recall: 0.3758 - val_loss: 0.0521 - val_accuracy: 0.9792 - val_precision: 0.9475 - val_recall: 0.4697\n",
      "Epoch 94/500\n",
      "600/600 [==============================] - 48s 79ms/step - loss: 0.0763 - accuracy: 0.9725 - precision: 0.7766 - recall: 0.3713 - val_loss: 0.0491 - val_accuracy: 0.9807 - val_precision: 0.9626 - val_recall: 0.5046\n",
      "Epoch 95/500\n",
      "600/600 [==============================] - 31s 51ms/step - loss: 0.0756 - accuracy: 0.9726 - precision: 0.7769 - recall: 0.3760 - val_loss: 0.0486 - val_accuracy: 0.9810 - val_precision: 0.9643 - val_recall: 0.5100\n",
      "Epoch 96/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0751 - accuracy: 0.9726 - precision: 0.7748 - recall: 0.3765 - val_loss: 0.0479 - val_accuracy: 0.9812 - val_precision: 0.9605 - val_recall: 0.5196\n",
      "Epoch 97/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0757 - accuracy: 0.9723 - precision: 0.7688 - recall: 0.3732 - val_loss: 0.0504 - val_accuracy: 0.9800 - val_precision: 0.9605 - val_recall: 0.4850\n",
      "Epoch 98/500\n",
      "600/600 [==============================] - 33s 55ms/step - loss: 0.0757 - accuracy: 0.9726 - precision: 0.7786 - recall: 0.3735 - val_loss: 0.0493 - val_accuracy: 0.9812 - val_precision: 0.9622 - val_recall: 0.5175\n",
      "Epoch 99/500\n",
      "600/600 [==============================] - 32s 53ms/step - loss: 0.0757 - accuracy: 0.9726 - precision: 0.7775 - recall: 0.3773 - val_loss: 0.0502 - val_accuracy: 0.9801 - val_precision: 0.9667 - val_recall: 0.4861\n",
      "Epoch 100/500\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0753 - accuracy: 0.9729 - precision: 0.7826 - recall: 0.3822 - val_loss: 0.0476 - val_accuracy: 0.9825 - val_precision: 0.9463 - val_recall: 0.5656\n",
      "Epoch 101/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0746 - accuracy: 0.9729 - precision: 0.7765 - recall: 0.3862 - val_loss: 0.0486 - val_accuracy: 0.9807 - val_precision: 0.9664 - val_recall: 0.5025\n",
      "Epoch 102/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0750 - accuracy: 0.9728 - precision: 0.7796 - recall: 0.3823 - val_loss: 0.0495 - val_accuracy: 0.9802 - val_precision: 0.9584 - val_recall: 0.4922\n",
      "Epoch 103/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0746 - accuracy: 0.9730 - precision: 0.7834 - recall: 0.3844 - val_loss: 0.0499 - val_accuracy: 0.9804 - val_precision: 0.9545 - val_recall: 0.5011\n",
      "Epoch 104/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0747 - accuracy: 0.9730 - precision: 0.7801 - recall: 0.3863 - val_loss: 0.0479 - val_accuracy: 0.9811 - val_precision: 0.9740 - val_recall: 0.5078\n",
      "Epoch 105/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0744 - accuracy: 0.9730 - precision: 0.7798 - recall: 0.3902 - val_loss: 0.0481 - val_accuracy: 0.9804 - val_precision: 0.9665 - val_recall: 0.4939\n",
      "Epoch 106/500\n",
      "600/600 [==============================] - 39s 65ms/step - loss: 0.0748 - accuracy: 0.9729 - precision: 0.7796 - recall: 0.3847 - val_loss: 0.0481 - val_accuracy: 0.9812 - val_precision: 0.9749 - val_recall: 0.5114\n",
      "Epoch 107/500\n",
      "600/600 [==============================] - 38s 63ms/step - loss: 0.0745 - accuracy: 0.9729 - precision: 0.7801 - recall: 0.3827 - val_loss: 0.0483 - val_accuracy: 0.9811 - val_precision: 0.9766 - val_recall: 0.5064\n",
      "Epoch 108/500\n",
      "600/600 [==============================] - 37s 62ms/step - loss: 0.0739 - accuracy: 0.9732 - precision: 0.7829 - recall: 0.3932 - val_loss: 0.0476 - val_accuracy: 0.9816 - val_precision: 0.9679 - val_recall: 0.5264\n",
      "Epoch 109/500\n",
      "600/600 [==============================] - 37s 62ms/step - loss: 0.0742 - accuracy: 0.9730 - precision: 0.7826 - recall: 0.3841 - val_loss: 0.0481 - val_accuracy: 0.9807 - val_precision: 0.9748 - val_recall: 0.4971\n",
      "Epoch 110/500\n",
      "600/600 [==============================] - 33s 55ms/step - loss: 0.0747 - accuracy: 0.9731 - precision: 0.7899 - recall: 0.3821 - val_loss: 0.0475 - val_accuracy: 0.9821 - val_precision: 0.9656 - val_recall: 0.5410\n",
      "Epoch 111/500\n",
      "600/600 [==============================] - 33s 54ms/step - loss: 0.0742 - accuracy: 0.9731 - precision: 0.7843 - recall: 0.3899 - val_loss: 0.0482 - val_accuracy: 0.9822 - val_precision: 0.9617 - val_recall: 0.5456\n",
      "Epoch 112/500\n",
      "600/600 [==============================] - 32s 53ms/step - loss: 0.0745 - accuracy: 0.9730 - precision: 0.7837 - recall: 0.3858 - val_loss: 0.0482 - val_accuracy: 0.9811 - val_precision: 0.9633 - val_recall: 0.5139\n",
      "Epoch 113/500\n",
      "600/600 [==============================] - 32s 54ms/step - loss: 0.0748 - accuracy: 0.9728 - precision: 0.7781 - recall: 0.3820 - val_loss: 0.0469 - val_accuracy: 0.9824 - val_precision: 0.9714 - val_recall: 0.5456\n",
      "Epoch 114/500\n",
      "600/600 [==============================] - 31s 52ms/step - loss: 0.0743 - accuracy: 0.9731 - precision: 0.7840 - recall: 0.3896 - val_loss: 0.0478 - val_accuracy: 0.9816 - val_precision: 0.9631 - val_recall: 0.5299\n",
      "Epoch 115/500\n",
      "600/600 [==============================] - 33s 55ms/step - loss: 0.0740 - accuracy: 0.9730 - precision: 0.7818 - recall: 0.3881 - val_loss: 0.0491 - val_accuracy: 0.9810 - val_precision: 0.9601 - val_recall: 0.5143\n",
      "Epoch 116/500\n",
      "600/600 [==============================] - 36s 60ms/step - loss: 0.0741 - accuracy: 0.9731 - precision: 0.7835 - recall: 0.3879 - val_loss: 0.0476 - val_accuracy: 0.9812 - val_precision: 0.9761 - val_recall: 0.5089\n",
      "Epoch 117/500\n",
      "600/600 [==============================] - 36s 61ms/step - loss: 0.0747 - accuracy: 0.9731 - precision: 0.7864 - recall: 0.3874 - val_loss: 0.0476 - val_accuracy: 0.9811 - val_precision: 0.9602 - val_recall: 0.5164\n",
      "Epoch 118/500\n",
      "600/600 [==============================] - 36s 60ms/step - loss: 0.0735 - accuracy: 0.9732 - precision: 0.7857 - recall: 0.3890 - val_loss: 0.0467 - val_accuracy: 0.9821 - val_precision: 0.9710 - val_recall: 0.5367\n",
      "Epoch 119/500\n",
      "600/600 [==============================] - 35s 58ms/step - loss: 0.0737 - accuracy: 0.9734 - precision: 0.7950 - recall: 0.3911 - val_loss: 0.0477 - val_accuracy: 0.9815 - val_precision: 0.9746 - val_recall: 0.5189\n",
      "Epoch 120/500\n",
      "600/600 [==============================] - 40s 66ms/step - loss: 0.0741 - accuracy: 0.9730 - precision: 0.7857 - recall: 0.3850 - val_loss: 0.0458 - val_accuracy: 0.9825 - val_precision: 0.9675 - val_recall: 0.5513\n",
      "Epoch 121/500\n",
      "600/600 [==============================] - 38s 64ms/step - loss: 0.0741 - accuracy: 0.9732 - precision: 0.7870 - recall: 0.3904 - val_loss: 0.0474 - val_accuracy: 0.9818 - val_precision: 0.9706 - val_recall: 0.5296\n",
      "Epoch 122/500\n",
      "600/600 [==============================] - 35s 59ms/step - loss: 0.0731 - accuracy: 0.9734 - precision: 0.7901 - recall: 0.3939 - val_loss: 0.0475 - val_accuracy: 0.9812 - val_precision: 0.9710 - val_recall: 0.5128\n",
      "Epoch 123/500\n",
      "600/600 [==============================] - 39s 65ms/step - loss: 0.0739 - accuracy: 0.9734 - precision: 0.7895 - recall: 0.3944 - val_loss: 0.0465 - val_accuracy: 0.9812 - val_precision: 0.9703 - val_recall: 0.5121\n",
      "Epoch 124/500\n",
      "600/600 [==============================] - 36s 60ms/step - loss: 0.0741 - accuracy: 0.9731 - precision: 0.7845 - recall: 0.3892 - val_loss: 0.0476 - val_accuracy: 0.9813 - val_precision: 0.9699 - val_recall: 0.5171\n",
      "Epoch 125/500\n",
      "600/600 [==============================] - 43s 71ms/step - loss: 0.0730 - accuracy: 0.9735 - precision: 0.7890 - recall: 0.3979 - val_loss: 0.0472 - val_accuracy: 0.9818 - val_precision: 0.9712 - val_recall: 0.5289\n",
      "Epoch 126/500\n",
      "600/600 [==============================] - 43s 71ms/step - loss: 0.0738 - accuracy: 0.9732 - precision: 0.7849 - recall: 0.3911 - val_loss: 0.0474 - val_accuracy: 0.9814 - val_precision: 0.9738 - val_recall: 0.5164\n",
      "Epoch 127/500\n",
      "600/600 [==============================] - 44s 73ms/step - loss: 0.0734 - accuracy: 0.9732 - precision: 0.7890 - recall: 0.3895 - val_loss: 0.0464 - val_accuracy: 0.9823 - val_precision: 0.9666 - val_recall: 0.5470\n",
      "Epoch 128/500\n",
      "600/600 [==============================] - 38s 63ms/step - loss: 0.0733 - accuracy: 0.9735 - precision: 0.7890 - recall: 0.3995 - val_loss: 0.0452 - val_accuracy: 0.9826 - val_precision: 0.9705 - val_recall: 0.5517\n",
      "Epoch 129/500\n",
      "600/600 [==============================] - 36s 60ms/step - loss: 0.0733 - accuracy: 0.9730 - precision: 0.7828 - recall: 0.3862 - val_loss: 0.0458 - val_accuracy: 0.9825 - val_precision: 0.9740 - val_recall: 0.5481\n",
      "Epoch 130/500\n",
      "600/600 [==============================] - 45s 75ms/step - loss: 0.0729 - accuracy: 0.9736 - precision: 0.7933 - recall: 0.3996 - val_loss: 0.0453 - val_accuracy: 0.9820 - val_precision: 0.9517 - val_recall: 0.5481\n",
      "Epoch 131/500\n",
      "600/600 [==============================] - 37s 61ms/step - loss: 0.0733 - accuracy: 0.9733 - precision: 0.7897 - recall: 0.3898 - val_loss: 0.0480 - val_accuracy: 0.9815 - val_precision: 0.9746 - val_recall: 0.5189\n",
      "Epoch 132/500\n",
      "600/600 [==============================] - 36s 61ms/step - loss: 0.0728 - accuracy: 0.9735 - precision: 0.7893 - recall: 0.3969 - val_loss: 0.0451 - val_accuracy: 0.9826 - val_precision: 0.9826 - val_recall: 0.5442\n",
      "Epoch 133/500\n",
      "600/600 [==============================] - 42s 71ms/step - loss: 0.0736 - accuracy: 0.9733 - precision: 0.7915 - recall: 0.3890 - val_loss: 0.0456 - val_accuracy: 0.9822 - val_precision: 0.9743 - val_recall: 0.5396\n",
      "Epoch 134/500\n",
      "600/600 [==============================] - 37s 62ms/step - loss: 0.0727 - accuracy: 0.9735 - precision: 0.7852 - recall: 0.4034 - val_loss: 0.0443 - val_accuracy: 0.9835 - val_precision: 0.9689 - val_recall: 0.5773\n",
      "Epoch 135/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0731 - accuracy: 0.9734 - precision: 0.7894 - recall: 0.3951 - val_loss: 0.0448 - val_accuracy: 0.9828 - val_precision: 0.9657 - val_recall: 0.5613\n",
      "Epoch 136/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0730 - accuracy: 0.9735 - precision: 0.7848 - recall: 0.4025 - val_loss: 0.0460 - val_accuracy: 0.9826 - val_precision: 0.9693 - val_recall: 0.5513\n",
      "Epoch 137/500\n",
      "600/600 [==============================] - 30s 50ms/step - loss: 0.0726 - accuracy: 0.9735 - precision: 0.7883 - recall: 0.4004 - val_loss: 0.0468 - val_accuracy: 0.9818 - val_precision: 0.9885 - val_recall: 0.5196\n",
      "Epoch 138/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0730 - accuracy: 0.9737 - precision: 0.7970 - recall: 0.4004 - val_loss: 0.0453 - val_accuracy: 0.9830 - val_precision: 0.9654 - val_recall: 0.5663\n",
      "Epoch 139/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0730 - accuracy: 0.9736 - precision: 0.7958 - recall: 0.3957 - val_loss: 0.0457 - val_accuracy: 0.9818 - val_precision: 0.9718 - val_recall: 0.5282\n",
      "Epoch 140/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0732 - accuracy: 0.9734 - precision: 0.7941 - recall: 0.3911 - val_loss: 0.0446 - val_accuracy: 0.9827 - val_precision: 0.9660 - val_recall: 0.5563\n",
      "Epoch 141/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0730 - accuracy: 0.9733 - precision: 0.7857 - recall: 0.3953 - val_loss: 0.0455 - val_accuracy: 0.9822 - val_precision: 0.9766 - val_recall: 0.5360\n",
      "Epoch 142/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0735 - accuracy: 0.9735 - precision: 0.7899 - recall: 0.3990 - val_loss: 0.0451 - val_accuracy: 0.9826 - val_precision: 0.9765 - val_recall: 0.5488\n",
      "Epoch 143/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0725 - accuracy: 0.9735 - precision: 0.7889 - recall: 0.3992 - val_loss: 0.0455 - val_accuracy: 0.9824 - val_precision: 0.9685 - val_recall: 0.5470\n",
      "Epoch 144/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0730 - accuracy: 0.9736 - precision: 0.7900 - recall: 0.4011 - val_loss: 0.0447 - val_accuracy: 0.9820 - val_precision: 0.9654 - val_recall: 0.5374\n",
      "Epoch 145/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0723 - accuracy: 0.9736 - precision: 0.7885 - recall: 0.4010 - val_loss: 0.0455 - val_accuracy: 0.9818 - val_precision: 0.9800 - val_recall: 0.5249\n",
      "Epoch 146/500\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 0.0731 - accuracy: 0.9733 - precision: 0.7851 - recall: 0.3945 - val_loss: 0.0444 - val_accuracy: 0.9828 - val_precision: 0.9703 - val_recall: 0.5581\n",
      "Epoch 147/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0724 - accuracy: 0.9738 - precision: 0.7988 - recall: 0.3996 - val_loss: 0.0448 - val_accuracy: 0.9823 - val_precision: 0.9774 - val_recall: 0.5385\n",
      "Epoch 148/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0724 - accuracy: 0.9735 - precision: 0.7882 - recall: 0.4007 - val_loss: 0.0466 - val_accuracy: 0.9823 - val_precision: 0.9719 - val_recall: 0.5424\n",
      "Epoch 149/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0723 - accuracy: 0.9735 - precision: 0.7918 - recall: 0.3977 - val_loss: 0.0437 - val_accuracy: 0.9833 - val_precision: 0.9675 - val_recall: 0.5734\n",
      "Epoch 150/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0717 - accuracy: 0.9740 - precision: 0.7939 - recall: 0.4135 - val_loss: 0.0453 - val_accuracy: 0.9824 - val_precision: 0.9738 - val_recall: 0.5438\n",
      "Epoch 151/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0723 - accuracy: 0.9737 - precision: 0.7904 - recall: 0.4052 - val_loss: 0.0453 - val_accuracy: 0.9821 - val_precision: 0.9734 - val_recall: 0.5353\n",
      "Epoch 152/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0721 - accuracy: 0.9738 - precision: 0.7915 - recall: 0.4062 - val_loss: 0.0448 - val_accuracy: 0.9841 - val_precision: 0.9611 - val_recall: 0.5984\n",
      "Epoch 153/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0725 - accuracy: 0.9735 - precision: 0.7873 - recall: 0.4006 - val_loss: 0.0441 - val_accuracy: 0.9841 - val_precision: 0.9660 - val_recall: 0.5966\n",
      "Epoch 154/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0727 - accuracy: 0.9735 - precision: 0.7870 - recall: 0.3993 - val_loss: 0.0439 - val_accuracy: 0.9832 - val_precision: 0.9685 - val_recall: 0.5695\n",
      "Epoch 155/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0721 - accuracy: 0.9738 - precision: 0.7886 - recall: 0.4090 - val_loss: 0.0444 - val_accuracy: 0.9832 - val_precision: 0.9691 - val_recall: 0.5695\n",
      "Epoch 156/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0726 - accuracy: 0.9738 - precision: 0.7956 - recall: 0.4054 - val_loss: 0.0449 - val_accuracy: 0.9838 - val_precision: 0.9732 - val_recall: 0.5823\n",
      "Epoch 157/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0721 - accuracy: 0.9738 - precision: 0.7926 - recall: 0.4078 - val_loss: 0.0443 - val_accuracy: 0.9832 - val_precision: 0.9685 - val_recall: 0.5702\n",
      "Epoch 158/500\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 0.0718 - accuracy: 0.9739 - precision: 0.7935 - recall: 0.4080 - val_loss: 0.0447 - val_accuracy: 0.9826 - val_precision: 0.9808 - val_recall: 0.5449\n",
      "Epoch 159/500\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 0.0711 - accuracy: 0.9740 - precision: 0.7952 - recall: 0.4099 - val_loss: 0.0434 - val_accuracy: 0.9837 - val_precision: 0.9609 - val_recall: 0.5873\n",
      "Epoch 160/500\n",
      "600/600 [==============================] - 24s 39ms/step - loss: 0.0717 - accuracy: 0.9739 - precision: 0.7945 - recall: 0.4081 - val_loss: 0.0433 - val_accuracy: 0.9836 - val_precision: 0.9702 - val_recall: 0.5795\n",
      "Epoch 161/500\n",
      "600/600 [==============================] - 23s 39ms/step - loss: 0.0721 - accuracy: 0.9737 - precision: 0.7883 - recall: 0.4071 - val_loss: 0.0454 - val_accuracy: 0.9827 - val_precision: 0.9677 - val_recall: 0.5552\n",
      "Epoch 162/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0724 - accuracy: 0.9740 - precision: 0.8025 - recall: 0.4069 - val_loss: 0.0429 - val_accuracy: 0.9835 - val_precision: 0.9775 - val_recall: 0.5723\n",
      "Epoch 163/500\n",
      "600/600 [==============================] - 27s 44ms/step - loss: 0.0726 - accuracy: 0.9737 - precision: 0.7922 - recall: 0.4015 - val_loss: 0.0432 - val_accuracy: 0.9835 - val_precision: 0.9740 - val_recall: 0.5745\n",
      "Epoch 164/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0715 - accuracy: 0.9740 - precision: 0.7959 - recall: 0.4100 - val_loss: 0.0440 - val_accuracy: 0.9830 - val_precision: 0.9811 - val_recall: 0.5560\n",
      "Epoch 165/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0717 - accuracy: 0.9739 - precision: 0.7905 - recall: 0.4135 - val_loss: 0.0435 - val_accuracy: 0.9828 - val_precision: 0.9750 - val_recall: 0.5549\n",
      "Epoch 166/500\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 0.0711 - accuracy: 0.9742 - precision: 0.8000 - recall: 0.4134 - val_loss: 0.0428 - val_accuracy: 0.9832 - val_precision: 0.9777 - val_recall: 0.5634\n",
      "Epoch 167/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0716 - accuracy: 0.9738 - precision: 0.7918 - recall: 0.4089 - val_loss: 0.0442 - val_accuracy: 0.9825 - val_precision: 0.9770 - val_recall: 0.5442\n",
      "Epoch 168/500\n",
      "600/600 [==============================] - 35s 59ms/step - loss: 0.0714 - accuracy: 0.9740 - precision: 0.7934 - recall: 0.4146 - val_loss: 0.0434 - val_accuracy: 0.9834 - val_precision: 0.9821 - val_recall: 0.5677\n",
      "Epoch 169/500\n",
      "600/600 [==============================] - 39s 65ms/step - loss: 0.0710 - accuracy: 0.9739 - precision: 0.7938 - recall: 0.4106 - val_loss: 0.0425 - val_accuracy: 0.9832 - val_precision: 0.9691 - val_recall: 0.5706\n",
      "Epoch 170/500\n",
      "600/600 [==============================] - 31s 52ms/step - loss: 0.0715 - accuracy: 0.9741 - precision: 0.7969 - recall: 0.4142 - val_loss: 0.0436 - val_accuracy: 0.9834 - val_precision: 0.9773 - val_recall: 0.5688\n",
      "Epoch 171/500\n",
      "600/600 [==============================] - 39s 64ms/step - loss: 0.0720 - accuracy: 0.9739 - precision: 0.7957 - recall: 0.4081 - val_loss: 0.0427 - val_accuracy: 0.9838 - val_precision: 0.9699 - val_recall: 0.5859\n",
      "Epoch 172/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0712 - accuracy: 0.9740 - precision: 0.7965 - recall: 0.4103 - val_loss: 0.0434 - val_accuracy: 0.9840 - val_precision: 0.9797 - val_recall: 0.5837\n",
      "Epoch 173/500\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0707 - accuracy: 0.9744 - precision: 0.8022 - recall: 0.4194 - val_loss: 0.0418 - val_accuracy: 0.9840 - val_precision: 0.9768 - val_recall: 0.5862\n",
      "Epoch 174/500\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 0.0714 - accuracy: 0.9740 - precision: 0.7932 - recall: 0.4124 - val_loss: 0.0438 - val_accuracy: 0.9829 - val_precision: 0.9774 - val_recall: 0.5556\n",
      "Epoch 175/500\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0712 - accuracy: 0.9743 - precision: 0.8008 - recall: 0.4184 - val_loss: 0.0425 - val_accuracy: 0.9836 - val_precision: 0.9817 - val_recall: 0.5720\n",
      "Epoch 176/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0719 - accuracy: 0.9739 - precision: 0.7942 - recall: 0.4069 - val_loss: 0.0431 - val_accuracy: 0.9836 - val_precision: 0.9811 - val_recall: 0.5734\n",
      "Epoch 177/500\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 0.0718 - accuracy: 0.9740 - precision: 0.7920 - recall: 0.4125 - val_loss: 0.0431 - val_accuracy: 0.9838 - val_precision: 0.9694 - val_recall: 0.5862\n",
      "Epoch 178/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0707 - accuracy: 0.9742 - precision: 0.8003 - recall: 0.4159 - val_loss: 0.0413 - val_accuracy: 0.9851 - val_precision: 0.9664 - val_recall: 0.6247\n",
      "Epoch 179/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0713 - accuracy: 0.9741 - precision: 0.7931 - recall: 0.4177 - val_loss: 0.0429 - val_accuracy: 0.9829 - val_precision: 0.9817 - val_recall: 0.5535\n",
      "Epoch 180/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0713 - accuracy: 0.9742 - precision: 0.7950 - recall: 0.4199 - val_loss: 0.0429 - val_accuracy: 0.9830 - val_precision: 0.9860 - val_recall: 0.5524\n",
      "Epoch 181/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0715 - accuracy: 0.9739 - precision: 0.7926 - recall: 0.4117 - val_loss: 0.0422 - val_accuracy: 0.9842 - val_precision: 0.9805 - val_recall: 0.5898\n",
      "Epoch 182/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0713 - accuracy: 0.9742 - precision: 0.7958 - recall: 0.4173 - val_loss: 0.0419 - val_accuracy: 0.9842 - val_precision: 0.9760 - val_recall: 0.5937\n",
      "Epoch 183/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0712 - accuracy: 0.9739 - precision: 0.7956 - recall: 0.4071 - val_loss: 0.0414 - val_accuracy: 0.9847 - val_precision: 0.9753 - val_recall: 0.6055\n",
      "Epoch 184/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0708 - accuracy: 0.9739 - precision: 0.7922 - recall: 0.4117 - val_loss: 0.0416 - val_accuracy: 0.9848 - val_precision: 0.9722 - val_recall: 0.6101\n",
      "Epoch 185/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0710 - accuracy: 0.9743 - precision: 0.7971 - recall: 0.4204 - val_loss: 0.0425 - val_accuracy: 0.9836 - val_precision: 0.9758 - val_recall: 0.5759\n",
      "Epoch 186/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0706 - accuracy: 0.9744 - precision: 0.8026 - recall: 0.4195 - val_loss: 0.0425 - val_accuracy: 0.9833 - val_precision: 0.9720 - val_recall: 0.5695\n",
      "Epoch 187/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0710 - accuracy: 0.9740 - precision: 0.7971 - recall: 0.4102 - val_loss: 0.0423 - val_accuracy: 0.9842 - val_precision: 0.9793 - val_recall: 0.5905\n",
      "Epoch 188/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0708 - accuracy: 0.9741 - precision: 0.7943 - recall: 0.4172 - val_loss: 0.0415 - val_accuracy: 0.9847 - val_precision: 0.9695 - val_recall: 0.6112\n",
      "Epoch 189/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0705 - accuracy: 0.9742 - precision: 0.7939 - recall: 0.4193 - val_loss: 0.0418 - val_accuracy: 0.9838 - val_precision: 0.9766 - val_recall: 0.5802\n",
      "Epoch 190/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0709 - accuracy: 0.9741 - precision: 0.7954 - recall: 0.4132 - val_loss: 0.0411 - val_accuracy: 0.9843 - val_precision: 0.9755 - val_recall: 0.5966\n",
      "Epoch 191/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0706 - accuracy: 0.9742 - precision: 0.7937 - recall: 0.4198 - val_loss: 0.0429 - val_accuracy: 0.9834 - val_precision: 0.9768 - val_recall: 0.5709\n",
      "Epoch 192/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0703 - accuracy: 0.9743 - precision: 0.7991 - recall: 0.4198 - val_loss: 0.0416 - val_accuracy: 0.9841 - val_precision: 0.9736 - val_recall: 0.5919\n",
      "Epoch 193/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0711 - accuracy: 0.9740 - precision: 0.7932 - recall: 0.4118 - val_loss: 0.0428 - val_accuracy: 0.9833 - val_precision: 0.9749 - val_recall: 0.5684\n",
      "Epoch 194/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0712 - accuracy: 0.9742 - precision: 0.7973 - recall: 0.4181 - val_loss: 0.0438 - val_accuracy: 0.9830 - val_precision: 0.9866 - val_recall: 0.5527\n",
      "Epoch 195/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0713 - accuracy: 0.9740 - precision: 0.7919 - recall: 0.4142 - val_loss: 0.0426 - val_accuracy: 0.9833 - val_precision: 0.9761 - val_recall: 0.5670\n",
      "Epoch 196/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0711 - accuracy: 0.9743 - precision: 0.8021 - recall: 0.4156 - val_loss: 0.0416 - val_accuracy: 0.9836 - val_precision: 0.9741 - val_recall: 0.5770\n",
      "Epoch 197/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0713 - accuracy: 0.9741 - precision: 0.7984 - recall: 0.4104 - val_loss: 0.0418 - val_accuracy: 0.9837 - val_precision: 0.9759 - val_recall: 0.5777\n",
      "Epoch 198/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0705 - accuracy: 0.9746 - precision: 0.8083 - recall: 0.4199 - val_loss: 0.0417 - val_accuracy: 0.9836 - val_precision: 0.9735 - val_recall: 0.5770\n",
      "Epoch 199/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0702 - accuracy: 0.9744 - precision: 0.7997 - recall: 0.4215 - val_loss: 0.0415 - val_accuracy: 0.9831 - val_precision: 0.9867 - val_recall: 0.5560\n",
      "Epoch 200/500\n",
      "600/600 [==============================] - 24s 41ms/step - loss: 0.0706 - accuracy: 0.9742 - precision: 0.7962 - recall: 0.4177 - val_loss: 0.0414 - val_accuracy: 0.9848 - val_precision: 0.9760 - val_recall: 0.6076\n",
      "Epoch 201/500\n",
      "600/600 [==============================] - 25s 41ms/step - loss: 0.0700 - accuracy: 0.9746 - precision: 0.8033 - recall: 0.4261 - val_loss: 0.0414 - val_accuracy: 0.9845 - val_precision: 0.9719 - val_recall: 0.6044\n",
      "Epoch 202/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0703 - accuracy: 0.9745 - precision: 0.8026 - recall: 0.4231 - val_loss: 0.0427 - val_accuracy: 0.9837 - val_precision: 0.9806 - val_recall: 0.5759\n",
      "Epoch 203/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0709 - accuracy: 0.9742 - precision: 0.7978 - recall: 0.4154 - val_loss: 0.0428 - val_accuracy: 0.9830 - val_precision: 0.9787 - val_recall: 0.5581\n",
      "Epoch 204/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0705 - accuracy: 0.9743 - precision: 0.8036 - recall: 0.4159 - val_loss: 0.0432 - val_accuracy: 0.9836 - val_precision: 0.9776 - val_recall: 0.5759\n",
      "Epoch 205/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0710 - accuracy: 0.9742 - precision: 0.8004 - recall: 0.4158 - val_loss: 0.0421 - val_accuracy: 0.9841 - val_precision: 0.9719 - val_recall: 0.5916\n",
      "Epoch 206/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0703 - accuracy: 0.9744 - precision: 0.8018 - recall: 0.4194 - val_loss: 0.0417 - val_accuracy: 0.9840 - val_precision: 0.9663 - val_recall: 0.5934\n",
      "Epoch 207/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0699 - accuracy: 0.9743 - precision: 0.7973 - recall: 0.4216 - val_loss: 0.0419 - val_accuracy: 0.9837 - val_precision: 0.9669 - val_recall: 0.5837\n",
      "Epoch 208/500\n",
      "600/600 [==============================] - 30s 50ms/step - loss: 0.0706 - accuracy: 0.9743 - precision: 0.7953 - recall: 0.4213 - val_loss: 0.0408 - val_accuracy: 0.9842 - val_precision: 0.9732 - val_recall: 0.5952\n",
      "Epoch 209/500\n",
      "600/600 [==============================] - 30s 51ms/step - loss: 0.0711 - accuracy: 0.9743 - precision: 0.7970 - recall: 0.4192 - val_loss: 0.0414 - val_accuracy: 0.9846 - val_precision: 0.9704 - val_recall: 0.6073\n",
      "Epoch 210/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0708 - accuracy: 0.9743 - precision: 0.7986 - recall: 0.4207 - val_loss: 0.0411 - val_accuracy: 0.9845 - val_precision: 0.9730 - val_recall: 0.6037\n",
      "Epoch 211/500\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0701 - accuracy: 0.9746 - precision: 0.8024 - recall: 0.4257 - val_loss: 0.0408 - val_accuracy: 0.9849 - val_precision: 0.9740 - val_recall: 0.6137\n",
      "Epoch 212/500\n",
      "600/600 [==============================] - 35s 58ms/step - loss: 0.0706 - accuracy: 0.9744 - precision: 0.7995 - recall: 0.4202 - val_loss: 0.0414 - val_accuracy: 0.9841 - val_precision: 0.9741 - val_recall: 0.5909\n",
      "Epoch 213/500\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0704 - accuracy: 0.9743 - precision: 0.7955 - recall: 0.4222 - val_loss: 0.0410 - val_accuracy: 0.9845 - val_precision: 0.9757 - val_recall: 0.6001\n",
      "Epoch 214/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0705 - accuracy: 0.9744 - precision: 0.7995 - recall: 0.4217 - val_loss: 0.0419 - val_accuracy: 0.9840 - val_precision: 0.9674 - val_recall: 0.5927\n",
      "Epoch 215/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0700 - accuracy: 0.9743 - precision: 0.8019 - recall: 0.4169 - val_loss: 0.0416 - val_accuracy: 0.9840 - val_precision: 0.9797 - val_recall: 0.5837\n",
      "Epoch 216/500\n",
      "600/600 [==============================] - 33s 56ms/step - loss: 0.0695 - accuracy: 0.9747 - precision: 0.8012 - recall: 0.4323 - val_loss: 0.0413 - val_accuracy: 0.9840 - val_precision: 0.9657 - val_recall: 0.5927\n",
      "Epoch 217/500\n",
      "600/600 [==============================] - 46s 77ms/step - loss: 0.0697 - accuracy: 0.9746 - precision: 0.8018 - recall: 0.4264 - val_loss: 0.0395 - val_accuracy: 0.9850 - val_precision: 0.9611 - val_recall: 0.6247\n",
      "Epoch 218/500\n",
      "600/600 [==============================] - 52s 87ms/step - loss: 0.0701 - accuracy: 0.9746 - precision: 0.8042 - recall: 0.4265 - val_loss: 0.0414 - val_accuracy: 0.9844 - val_precision: 0.9691 - val_recall: 0.6033\n",
      "Epoch 219/500\n",
      "600/600 [==============================] - 44s 73ms/step - loss: 0.0699 - accuracy: 0.9745 - precision: 0.8020 - recall: 0.4236 - val_loss: 0.0409 - val_accuracy: 0.9836 - val_precision: 0.9770 - val_recall: 0.5741\n",
      "Epoch 220/500\n",
      "600/600 [==============================] - 36s 60ms/step - loss: 0.0695 - accuracy: 0.9746 - precision: 0.8036 - recall: 0.4253 - val_loss: 0.0405 - val_accuracy: 0.9852 - val_precision: 0.9716 - val_recall: 0.6222\n",
      "Epoch 221/500\n",
      "600/600 [==============================] - 39s 65ms/step - loss: 0.0705 - accuracy: 0.9742 - precision: 0.7967 - recall: 0.4186 - val_loss: 0.0408 - val_accuracy: 0.9840 - val_precision: 0.9610 - val_recall: 0.5973\n",
      "Epoch 222/500\n",
      "600/600 [==============================] - 33s 55ms/step - loss: 0.0702 - accuracy: 0.9743 - precision: 0.7954 - recall: 0.4232 - val_loss: 0.0409 - val_accuracy: 0.9849 - val_precision: 0.9682 - val_recall: 0.6180\n",
      "Epoch 223/500\n",
      "600/600 [==============================] - 37s 61ms/step - loss: 0.0699 - accuracy: 0.9743 - precision: 0.7962 - recall: 0.4224 - val_loss: 0.0407 - val_accuracy: 0.9833 - val_precision: 0.9796 - val_recall: 0.5649\n",
      "Epoch 224/500\n",
      "600/600 [==============================] - 46s 77ms/step - loss: 0.0701 - accuracy: 0.9746 - precision: 0.8046 - recall: 0.4244 - val_loss: 0.0414 - val_accuracy: 0.9839 - val_precision: 0.9733 - val_recall: 0.5855\n",
      "Epoch 225/500\n",
      "600/600 [==============================] - 37s 62ms/step - loss: 0.0709 - accuracy: 0.9741 - precision: 0.7967 - recall: 0.4127 - val_loss: 0.0418 - val_accuracy: 0.9847 - val_precision: 0.9765 - val_recall: 0.6066\n",
      "Epoch 226/500\n",
      "600/600 [==============================] - 30s 51ms/step - loss: 0.0704 - accuracy: 0.9743 - precision: 0.8004 - recall: 0.4177 - val_loss: 0.0411 - val_accuracy: 0.9842 - val_precision: 0.9748 - val_recall: 0.5919\n",
      "Epoch 227/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0702 - accuracy: 0.9743 - precision: 0.7985 - recall: 0.4208 - val_loss: 0.0403 - val_accuracy: 0.9853 - val_precision: 0.9616 - val_recall: 0.6333\n",
      "Epoch 228/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0699 - accuracy: 0.9745 - precision: 0.7990 - recall: 0.4242 - val_loss: 0.0412 - val_accuracy: 0.9843 - val_precision: 0.9783 - val_recall: 0.5948\n",
      "Epoch 229/500\n",
      "600/600 [==============================] - 25s 42ms/step - loss: 0.0702 - accuracy: 0.9742 - precision: 0.7969 - recall: 0.4166 - val_loss: 0.0420 - val_accuracy: 0.9838 - val_precision: 0.9848 - val_recall: 0.5759\n",
      "Epoch 230/500\n",
      "600/600 [==============================] - 35s 59ms/step - loss: 0.0701 - accuracy: 0.9744 - precision: 0.7998 - recall: 0.4214 - val_loss: 0.0409 - val_accuracy: 0.9840 - val_precision: 0.9791 - val_recall: 0.5852\n",
      "Epoch 231/500\n",
      "600/600 [==============================] - 34s 57ms/step - loss: 0.0701 - accuracy: 0.9744 - precision: 0.8036 - recall: 0.4181 - val_loss: 0.0417 - val_accuracy: 0.9843 - val_precision: 0.9755 - val_recall: 0.5952\n",
      "Epoch 232/500\n",
      "600/600 [==============================] - 33s 54ms/step - loss: 0.0698 - accuracy: 0.9745 - precision: 0.8016 - recall: 0.4233 - val_loss: 0.0404 - val_accuracy: 0.9846 - val_precision: 0.9725 - val_recall: 0.6058\n",
      "Epoch 233/500\n",
      "600/600 [==============================] - 31s 52ms/step - loss: 0.0702 - accuracy: 0.9743 - precision: 0.7994 - recall: 0.4184 - val_loss: 0.0407 - val_accuracy: 0.9848 - val_precision: 0.9798 - val_recall: 0.6055\n",
      "Epoch 234/500\n",
      "600/600 [==============================] - 30s 50ms/step - loss: 0.0696 - accuracy: 0.9744 - precision: 0.7991 - recall: 0.4239 - val_loss: 0.0402 - val_accuracy: 0.9848 - val_precision: 0.9691 - val_recall: 0.6140\n",
      "Epoch 235/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0696 - accuracy: 0.9745 - precision: 0.8019 - recall: 0.4243 - val_loss: 0.0409 - val_accuracy: 0.9842 - val_precision: 0.9630 - val_recall: 0.6023\n",
      "Epoch 236/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0696 - accuracy: 0.9743 - precision: 0.8042 - recall: 0.4157 - val_loss: 0.0397 - val_accuracy: 0.9848 - val_precision: 0.9815 - val_recall: 0.6041\n",
      "Epoch 237/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0697 - accuracy: 0.9747 - precision: 0.8037 - recall: 0.4304 - val_loss: 0.0409 - val_accuracy: 0.9845 - val_precision: 0.9763 - val_recall: 0.6016\n",
      "Epoch 238/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0698 - accuracy: 0.9744 - precision: 0.7991 - recall: 0.4233 - val_loss: 0.0392 - val_accuracy: 0.9852 - val_precision: 0.9732 - val_recall: 0.6212\n",
      "Epoch 239/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0698 - accuracy: 0.9748 - precision: 0.8045 - recall: 0.4322 - val_loss: 0.0399 - val_accuracy: 0.9848 - val_precision: 0.9782 - val_recall: 0.6083\n",
      "Epoch 240/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0699 - accuracy: 0.9743 - precision: 0.7977 - recall: 0.4195 - val_loss: 0.0405 - val_accuracy: 0.9845 - val_precision: 0.9740 - val_recall: 0.6019\n",
      "Epoch 241/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0697 - accuracy: 0.9748 - precision: 0.8084 - recall: 0.4277 - val_loss: 0.0414 - val_accuracy: 0.9852 - val_precision: 0.9732 - val_recall: 0.6208\n",
      "Epoch 242/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0698 - accuracy: 0.9745 - precision: 0.8014 - recall: 0.4239 - val_loss: 0.0415 - val_accuracy: 0.9838 - val_precision: 0.9824 - val_recall: 0.5770\n",
      "Epoch 243/500\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0694 - accuracy: 0.9746 - precision: 0.7997 - recall: 0.4290 - val_loss: 0.0415 - val_accuracy: 0.9839 - val_precision: 0.9837 - val_recall: 0.5791\n",
      "Epoch 244/500\n",
      "600/600 [==============================] - 30s 50ms/step - loss: 0.0697 - accuracy: 0.9746 - precision: 0.8029 - recall: 0.4274 - val_loss: 0.0408 - val_accuracy: 0.9858 - val_precision: 0.9718 - val_recall: 0.6379\n",
      "Epoch 245/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0690 - accuracy: 0.9750 - precision: 0.8068 - recall: 0.4359 - val_loss: 0.0403 - val_accuracy: 0.9843 - val_precision: 0.9760 - val_recall: 0.5952\n",
      "Epoch 246/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0698 - accuracy: 0.9744 - precision: 0.7967 - recall: 0.4232 - val_loss: 0.0402 - val_accuracy: 0.9850 - val_precision: 0.9816 - val_recall: 0.6098\n",
      "Epoch 247/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0706 - accuracy: 0.9743 - precision: 0.7993 - recall: 0.4203 - val_loss: 0.0420 - val_accuracy: 0.9838 - val_precision: 0.9778 - val_recall: 0.5795\n",
      "Epoch 248/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0700 - accuracy: 0.9746 - precision: 0.8032 - recall: 0.4241 - val_loss: 0.0403 - val_accuracy: 0.9849 - val_precision: 0.9744 - val_recall: 0.6115\n",
      "Epoch 249/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0695 - accuracy: 0.9748 - precision: 0.8067 - recall: 0.4298 - val_loss: 0.0397 - val_accuracy: 0.9848 - val_precision: 0.9815 - val_recall: 0.6062\n",
      "Epoch 250/500\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0694 - accuracy: 0.9747 - precision: 0.8071 - recall: 0.4273 - val_loss: 0.0411 - val_accuracy: 0.9840 - val_precision: 0.9803 - val_recall: 0.5841\n",
      "Epoch 251/500\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0694 - accuracy: 0.9750 - precision: 0.8065 - recall: 0.4356 - val_loss: 0.0396 - val_accuracy: 0.9853 - val_precision: 0.9655 - val_recall: 0.6287\n",
      "Epoch 252/500\n",
      "600/600 [==============================] - 30s 51ms/step - loss: 0.0696 - accuracy: 0.9745 - precision: 0.8014 - recall: 0.4236 - val_loss: 0.0400 - val_accuracy: 0.9845 - val_precision: 0.9532 - val_recall: 0.6165\n",
      "Epoch 253/500\n",
      "600/600 [==============================] - 30s 50ms/step - loss: 0.0698 - accuracy: 0.9743 - precision: 0.7943 - recall: 0.4222 - val_loss: 0.0407 - val_accuracy: 0.9846 - val_precision: 0.9769 - val_recall: 0.6033\n",
      "Epoch 254/500\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0698 - accuracy: 0.9748 - precision: 0.8060 - recall: 0.4294 - val_loss: 0.0397 - val_accuracy: 0.9848 - val_precision: 0.9760 - val_recall: 0.6094\n",
      "Epoch 255/500\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0692 - accuracy: 0.9749 - precision: 0.8074 - recall: 0.4311 - val_loss: 0.0408 - val_accuracy: 0.9845 - val_precision: 0.9790 - val_recall: 0.5987\n",
      "Epoch 256/500\n",
      "600/600 [==============================] - 26s 43ms/step - loss: 0.0690 - accuracy: 0.9749 - precision: 0.8081 - recall: 0.4332 - val_loss: 0.0394 - val_accuracy: 0.9850 - val_precision: 0.9741 - val_recall: 0.6158\n",
      "Epoch 257/500\n",
      "600/600 [==============================] - 27s 44ms/step - loss: 0.0694 - accuracy: 0.9747 - precision: 0.8013 - recall: 0.4322 - val_loss: 0.0388 - val_accuracy: 0.9856 - val_precision: 0.9727 - val_recall: 0.6340\n",
      "Epoch 258/500\n",
      "600/600 [==============================] - 26s 44ms/step - loss: 0.0696 - accuracy: 0.9748 - precision: 0.8060 - recall: 0.4305 - val_loss: 0.0400 - val_accuracy: 0.9850 - val_precision: 0.9794 - val_recall: 0.6108\n",
      "Epoch 259/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0687 - accuracy: 0.9750 - precision: 0.8114 - recall: 0.4336 - val_loss: 0.0394 - val_accuracy: 0.9856 - val_precision: 0.9680 - val_recall: 0.6361\n",
      "Epoch 260/500\n",
      "600/600 [==============================] - 24s 40ms/step - loss: 0.0689 - accuracy: 0.9751 - precision: 0.8159 - recall: 0.4331 - val_loss: 0.0400 - val_accuracy: 0.9850 - val_precision: 0.9641 - val_recall: 0.6230\n",
      "Epoch 261/500\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0692 - accuracy: 0.9748 - precision: 0.8086 - recall: 0.4293 - val_loss: 0.0409 - val_accuracy: 0.9843 - val_precision: 0.9817 - val_recall: 0.5912\n",
      "Epoch 262/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0693 - accuracy: 0.9747 - precision: 0.8066 - recall: 0.4269 - val_loss: 0.0399 - val_accuracy: 0.9853 - val_precision: 0.9841 - val_recall: 0.6176\n",
      "Epoch 263/500\n",
      "600/600 [==============================] - 30s 49ms/step - loss: 0.0696 - accuracy: 0.9747 - precision: 0.8056 - recall: 0.4265 - val_loss: 0.0400 - val_accuracy: 0.9852 - val_precision: 0.9629 - val_recall: 0.6290\n",
      "Epoch 264/500\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0692 - accuracy: 0.9747 - precision: 0.8038 - recall: 0.4273 - val_loss: 0.0396 - val_accuracy: 0.9848 - val_precision: 0.9777 - val_recall: 0.6087\n",
      "Epoch 265/500\n",
      "600/600 [==============================] - 39s 65ms/step - loss: 0.0690 - accuracy: 0.9749 - precision: 0.8062 - recall: 0.4322 - val_loss: 0.0401 - val_accuracy: 0.9848 - val_precision: 0.9809 - val_recall: 0.6048\n",
      "Epoch 266/500\n",
      "600/600 [==============================] - 32s 54ms/step - loss: 0.0699 - accuracy: 0.9746 - precision: 0.8039 - recall: 0.4265 - val_loss: 0.0391 - val_accuracy: 0.9852 - val_precision: 0.9711 - val_recall: 0.6222\n",
      "Epoch 267/500\n",
      "600/600 [==============================] - 40s 67ms/step - loss: 0.0695 - accuracy: 0.9748 - precision: 0.8017 - recall: 0.4345 - val_loss: 0.0398 - val_accuracy: 0.9843 - val_precision: 0.9822 - val_recall: 0.5909\n",
      "Epoch 268/500\n",
      "600/600 [==============================] - 32s 54ms/step - loss: 0.0698 - accuracy: 0.9745 - precision: 0.8024 - recall: 0.4233 - val_loss: 0.0401 - val_accuracy: 0.9851 - val_precision: 0.9768 - val_recall: 0.6165\n",
      "Epoch 269/500\n",
      "600/600 [==============================] - 40842s 68s/step - loss: 0.0686 - accuracy: 0.9750 - precision: 0.8036 - recall: 0.4380 - val_loss: 0.0408 - val_accuracy: 0.9844 - val_precision: 0.9829 - val_recall: 0.5927\n",
      "Epoch 270/500\n",
      "600/600 [==============================] - 36s 60ms/step - loss: 0.0697 - accuracy: 0.9749 - precision: 0.8081 - recall: 0.4304 - val_loss: 0.0398 - val_accuracy: 0.9855 - val_precision: 0.9757 - val_recall: 0.6283\n",
      "Epoch 271/500\n",
      "600/600 [==============================] - 32s 53ms/step - loss: 0.0691 - accuracy: 0.9747 - precision: 0.8047 - recall: 0.4265 - val_loss: 0.0379 - val_accuracy: 0.9861 - val_precision: 0.9608 - val_recall: 0.6547\n",
      "Epoch 272/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0693 - accuracy: 0.9747 - precision: 0.8021 - recall: 0.4293 - val_loss: 0.0396 - val_accuracy: 0.9850 - val_precision: 0.9720 - val_recall: 0.6180\n",
      "Epoch 273/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0688 - accuracy: 0.9747 - precision: 0.8037 - recall: 0.4300 - val_loss: 0.0409 - val_accuracy: 0.9838 - val_precision: 0.9682 - val_recall: 0.5866\n",
      "Epoch 274/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0685 - accuracy: 0.9750 - precision: 0.8115 - recall: 0.4330 - val_loss: 0.0391 - val_accuracy: 0.9851 - val_precision: 0.9747 - val_recall: 0.6187\n",
      "Epoch 275/500\n",
      "600/600 [==============================] - 30s 51ms/step - loss: 0.0694 - accuracy: 0.9747 - precision: 0.8026 - recall: 0.4285 - val_loss: 0.0397 - val_accuracy: 0.9848 - val_precision: 0.9787 - val_recall: 0.6062\n",
      "Epoch 276/500\n",
      "600/600 [==============================] - 30s 50ms/step - loss: 0.0696 - accuracy: 0.9749 - precision: 0.8066 - recall: 0.4325 - val_loss: 0.0390 - val_accuracy: 0.9859 - val_precision: 0.9781 - val_recall: 0.6376\n",
      "Epoch 277/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0689 - accuracy: 0.9749 - precision: 0.8107 - recall: 0.4310 - val_loss: 0.0400 - val_accuracy: 0.9852 - val_precision: 0.9785 - val_recall: 0.6172\n",
      "Epoch 278/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0688 - accuracy: 0.9750 - precision: 0.8102 - recall: 0.4351 - val_loss: 0.0394 - val_accuracy: 0.9850 - val_precision: 0.9828 - val_recall: 0.6098\n",
      "Epoch 279/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0693 - accuracy: 0.9748 - precision: 0.8036 - recall: 0.4327 - val_loss: 0.0389 - val_accuracy: 0.9852 - val_precision: 0.9796 - val_recall: 0.6169\n",
      "Epoch 280/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0685 - accuracy: 0.9751 - precision: 0.8105 - recall: 0.4362 - val_loss: 0.0399 - val_accuracy: 0.9848 - val_precision: 0.9793 - val_recall: 0.6062\n",
      "Epoch 281/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0688 - accuracy: 0.9750 - precision: 0.8144 - recall: 0.4319 - val_loss: 0.0383 - val_accuracy: 0.9859 - val_precision: 0.9694 - val_recall: 0.6433\n",
      "Epoch 282/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0690 - accuracy: 0.9748 - precision: 0.8027 - recall: 0.4316 - val_loss: 0.0398 - val_accuracy: 0.9847 - val_precision: 0.9748 - val_recall: 0.6066\n",
      "Epoch 283/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0689 - accuracy: 0.9748 - precision: 0.8011 - recall: 0.4334 - val_loss: 0.0406 - val_accuracy: 0.9844 - val_precision: 0.9835 - val_recall: 0.5941\n",
      "Epoch 284/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0690 - accuracy: 0.9748 - precision: 0.8032 - recall: 0.4315 - val_loss: 0.0399 - val_accuracy: 0.9850 - val_precision: 0.9805 - val_recall: 0.6105\n",
      "Epoch 285/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0688 - accuracy: 0.9750 - precision: 0.8095 - recall: 0.4331 - val_loss: 0.0404 - val_accuracy: 0.9849 - val_precision: 0.9872 - val_recall: 0.6044\n",
      "Epoch 286/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0685 - accuracy: 0.9748 - precision: 0.8055 - recall: 0.4302 - val_loss: 0.0397 - val_accuracy: 0.9846 - val_precision: 0.9836 - val_recall: 0.5976\n",
      "Epoch 287/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0691 - accuracy: 0.9747 - precision: 0.8026 - recall: 0.4307 - val_loss: 0.0396 - val_accuracy: 0.9847 - val_precision: 0.9865 - val_recall: 0.5994\n",
      "Epoch 288/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0693 - accuracy: 0.9746 - precision: 0.8028 - recall: 0.4262 - val_loss: 0.0398 - val_accuracy: 0.9847 - val_precision: 0.9803 - val_recall: 0.6023\n",
      "Epoch 289/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0685 - accuracy: 0.9750 - precision: 0.8061 - recall: 0.4389 - val_loss: 0.0390 - val_accuracy: 0.9856 - val_precision: 0.9680 - val_recall: 0.6358\n",
      "Epoch 290/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0696 - accuracy: 0.9746 - precision: 0.8018 - recall: 0.4286 - val_loss: 0.0389 - val_accuracy: 0.9855 - val_precision: 0.9881 - val_recall: 0.6212\n",
      "Epoch 291/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0688 - accuracy: 0.9749 - precision: 0.8102 - recall: 0.4315 - val_loss: 0.0390 - val_accuracy: 0.9854 - val_precision: 0.9842 - val_recall: 0.6205\n",
      "Epoch 292/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0683 - accuracy: 0.9750 - precision: 0.8096 - recall: 0.4342 - val_loss: 0.0398 - val_accuracy: 0.9851 - val_precision: 0.9890 - val_recall: 0.6091\n",
      "Epoch 293/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0692 - accuracy: 0.9749 - precision: 0.8100 - recall: 0.4291 - val_loss: 0.0385 - val_accuracy: 0.9857 - val_precision: 0.9806 - val_recall: 0.6315\n",
      "Epoch 294/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0690 - accuracy: 0.9748 - precision: 0.8044 - recall: 0.4333 - val_loss: 0.0394 - val_accuracy: 0.9858 - val_precision: 0.9849 - val_recall: 0.6297\n",
      "Epoch 295/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0693 - accuracy: 0.9747 - precision: 0.8056 - recall: 0.4259 - val_loss: 0.0386 - val_accuracy: 0.9857 - val_precision: 0.9686 - val_recall: 0.6386\n",
      "Epoch 296/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0691 - accuracy: 0.9749 - precision: 0.8099 - recall: 0.4315 - val_loss: 0.0391 - val_accuracy: 0.9857 - val_precision: 0.9849 - val_recall: 0.6269\n",
      "Epoch 297/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0690 - accuracy: 0.9749 - precision: 0.8062 - recall: 0.4321 - val_loss: 0.0400 - val_accuracy: 0.9848 - val_precision: 0.9771 - val_recall: 0.6069\n",
      "Epoch 298/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0689 - accuracy: 0.9748 - precision: 0.8061 - recall: 0.4306 - val_loss: 0.0390 - val_accuracy: 0.9860 - val_precision: 0.9767 - val_recall: 0.6422\n",
      "Epoch 299/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0684 - accuracy: 0.9750 - precision: 0.8034 - recall: 0.4395 - val_loss: 0.0382 - val_accuracy: 0.9857 - val_precision: 0.9780 - val_recall: 0.6333\n",
      "Epoch 300/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0689 - accuracy: 0.9750 - precision: 0.8068 - recall: 0.4352 - val_loss: 0.0381 - val_accuracy: 0.9854 - val_precision: 0.9782 - val_recall: 0.6240\n",
      "Epoch 301/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0689 - accuracy: 0.9750 - precision: 0.8097 - recall: 0.4356 - val_loss: 0.0402 - val_accuracy: 0.9846 - val_precision: 0.9899 - val_recall: 0.5941\n",
      "Epoch 302/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0685 - accuracy: 0.9749 - precision: 0.8041 - recall: 0.4343 - val_loss: 0.0390 - val_accuracy: 0.9856 - val_precision: 0.9779 - val_recall: 0.6297\n",
      "Epoch 303/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0691 - accuracy: 0.9748 - precision: 0.8057 - recall: 0.4305 - val_loss: 0.0395 - val_accuracy: 0.9848 - val_precision: 0.9771 - val_recall: 0.6080\n",
      "Epoch 304/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0693 - accuracy: 0.9747 - precision: 0.8056 - recall: 0.4260 - val_loss: 0.0388 - val_accuracy: 0.9859 - val_precision: 0.9770 - val_recall: 0.6372\n",
      "Epoch 305/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0687 - accuracy: 0.9752 - precision: 0.8125 - recall: 0.4382 - val_loss: 0.0388 - val_accuracy: 0.9850 - val_precision: 0.9889 - val_recall: 0.6055\n",
      "Epoch 306/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0691 - accuracy: 0.9750 - precision: 0.8100 - recall: 0.4325 - val_loss: 0.0391 - val_accuracy: 0.9848 - val_precision: 0.9788 - val_recall: 0.6076\n",
      "Epoch 307/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0688 - accuracy: 0.9748 - precision: 0.8065 - recall: 0.4303 - val_loss: 0.0389 - val_accuracy: 0.9855 - val_precision: 0.9751 - val_recall: 0.6279\n",
      "Epoch 308/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0685 - accuracy: 0.9750 - precision: 0.8091 - recall: 0.4351 - val_loss: 0.0390 - val_accuracy: 0.9852 - val_precision: 0.9851 - val_recall: 0.6144\n",
      "Epoch 309/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0689 - accuracy: 0.9748 - precision: 0.8067 - recall: 0.4281 - val_loss: 0.0391 - val_accuracy: 0.9851 - val_precision: 0.9795 - val_recall: 0.6144\n",
      "Epoch 310/500\n",
      "600/600 [==============================] - 30s 50ms/step - loss: 0.0688 - accuracy: 0.9748 - precision: 0.8030 - recall: 0.4333 - val_loss: 0.0390 - val_accuracy: 0.9857 - val_precision: 0.9748 - val_recall: 0.6336\n",
      "Epoch 311/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0683 - accuracy: 0.9754 - precision: 0.8145 - recall: 0.4436 - val_loss: 0.0381 - val_accuracy: 0.9860 - val_precision: 0.9725 - val_recall: 0.6429\n",
      "Epoch 312/500\n",
      "600/600 [==============================] - 30s 50ms/step - loss: 0.0684 - accuracy: 0.9747 - precision: 0.8022 - recall: 0.4292 - val_loss: 0.0393 - val_accuracy: 0.9848 - val_precision: 0.9765 - val_recall: 0.6076\n",
      "Epoch 313/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0685 - accuracy: 0.9749 - precision: 0.8049 - recall: 0.4343 - val_loss: 0.0396 - val_accuracy: 0.9849 - val_precision: 0.9761 - val_recall: 0.6112\n",
      "Epoch 314/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0684 - accuracy: 0.9752 - precision: 0.8101 - recall: 0.4395 - val_loss: 0.0379 - val_accuracy: 0.9858 - val_precision: 0.9687 - val_recall: 0.6401\n",
      "Epoch 315/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0684 - accuracy: 0.9751 - precision: 0.8081 - recall: 0.4400 - val_loss: 0.0390 - val_accuracy: 0.9855 - val_precision: 0.9736 - val_recall: 0.6304\n",
      "Epoch 316/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0687 - accuracy: 0.9749 - precision: 0.8033 - recall: 0.4378 - val_loss: 0.0387 - val_accuracy: 0.9858 - val_precision: 0.9791 - val_recall: 0.6329\n",
      "Epoch 317/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0690 - accuracy: 0.9750 - precision: 0.8087 - recall: 0.4361 - val_loss: 0.0399 - val_accuracy: 0.9847 - val_precision: 0.9820 - val_recall: 0.6033\n",
      "Epoch 318/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0679 - accuracy: 0.9752 - precision: 0.8103 - recall: 0.4410 - val_loss: 0.0389 - val_accuracy: 0.9858 - val_precision: 0.9765 - val_recall: 0.6361\n",
      "Epoch 319/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0685 - accuracy: 0.9750 - precision: 0.8079 - recall: 0.4354 - val_loss: 0.0390 - val_accuracy: 0.9856 - val_precision: 0.9805 - val_recall: 0.6272\n",
      "Epoch 320/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0683 - accuracy: 0.9749 - precision: 0.8078 - recall: 0.4321 - val_loss: 0.0382 - val_accuracy: 0.9858 - val_precision: 0.9749 - val_recall: 0.6365\n",
      "Epoch 321/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0685 - accuracy: 0.9749 - precision: 0.8092 - recall: 0.4305 - val_loss: 0.0376 - val_accuracy: 0.9864 - val_precision: 0.9725 - val_recall: 0.6561\n",
      "Epoch 322/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0696 - accuracy: 0.9749 - precision: 0.8045 - recall: 0.4344 - val_loss: 0.0394 - val_accuracy: 0.9856 - val_precision: 0.9747 - val_recall: 0.6319\n",
      "Epoch 323/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0683 - accuracy: 0.9752 - precision: 0.8116 - recall: 0.4411 - val_loss: 0.0389 - val_accuracy: 0.9857 - val_precision: 0.9806 - val_recall: 0.6297\n",
      "Epoch 324/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0682 - accuracy: 0.9753 - precision: 0.8131 - recall: 0.4417 - val_loss: 0.0386 - val_accuracy: 0.9860 - val_precision: 0.9803 - val_recall: 0.6386\n",
      "Epoch 325/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0688 - accuracy: 0.9747 - precision: 0.8015 - recall: 0.4298 - val_loss: 0.0388 - val_accuracy: 0.9857 - val_precision: 0.9790 - val_recall: 0.6326\n",
      "Epoch 326/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0684 - accuracy: 0.9747 - precision: 0.8072 - recall: 0.4249 - val_loss: 0.0375 - val_accuracy: 0.9861 - val_precision: 0.9742 - val_recall: 0.6465\n",
      "Epoch 327/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0683 - accuracy: 0.9751 - precision: 0.8049 - recall: 0.4404 - val_loss: 0.0388 - val_accuracy: 0.9860 - val_precision: 0.9835 - val_recall: 0.6372\n",
      "Epoch 328/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0689 - accuracy: 0.9748 - precision: 0.8094 - recall: 0.4280 - val_loss: 0.0380 - val_accuracy: 0.9857 - val_precision: 0.9801 - val_recall: 0.6308\n",
      "Epoch 329/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0682 - accuracy: 0.9752 - precision: 0.8095 - recall: 0.4412 - val_loss: 0.0392 - val_accuracy: 0.9856 - val_precision: 0.9887 - val_recall: 0.6233\n",
      "Epoch 330/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0681 - accuracy: 0.9753 - precision: 0.8116 - recall: 0.4431 - val_loss: 0.0375 - val_accuracy: 0.9862 - val_precision: 0.9789 - val_recall: 0.6440\n",
      "Epoch 331/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0684 - accuracy: 0.9750 - precision: 0.8087 - recall: 0.4360 - val_loss: 0.0381 - val_accuracy: 0.9864 - val_precision: 0.9740 - val_recall: 0.6529\n",
      "Epoch 332/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0681 - accuracy: 0.9751 - precision: 0.8090 - recall: 0.4392 - val_loss: 0.0377 - val_accuracy: 0.9863 - val_precision: 0.9709 - val_recall: 0.6529\n",
      "Epoch 333/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0685 - accuracy: 0.9751 - precision: 0.8107 - recall: 0.4362 - val_loss: 0.0380 - val_accuracy: 0.9857 - val_precision: 0.9758 - val_recall: 0.6333\n",
      "Epoch 334/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0681 - accuracy: 0.9751 - precision: 0.8066 - recall: 0.4400 - val_loss: 0.0381 - val_accuracy: 0.9856 - val_precision: 0.9784 - val_recall: 0.6301\n",
      "Epoch 335/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0675 - accuracy: 0.9752 - precision: 0.8112 - recall: 0.4387 - val_loss: 0.0368 - val_accuracy: 0.9863 - val_precision: 0.9733 - val_recall: 0.6507\n",
      "Epoch 336/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0682 - accuracy: 0.9750 - precision: 0.8062 - recall: 0.4370 - val_loss: 0.0392 - val_accuracy: 0.9857 - val_precision: 0.9743 - val_recall: 0.6354\n",
      "Epoch 337/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0685 - accuracy: 0.9749 - precision: 0.8010 - recall: 0.4381 - val_loss: 0.0385 - val_accuracy: 0.9857 - val_precision: 0.9707 - val_recall: 0.6379\n",
      "Epoch 338/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0684 - accuracy: 0.9749 - precision: 0.8055 - recall: 0.4346 - val_loss: 0.0379 - val_accuracy: 0.9862 - val_precision: 0.9708 - val_recall: 0.6518\n",
      "Epoch 339/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0680 - accuracy: 0.9751 - precision: 0.8035 - recall: 0.4445 - val_loss: 0.0370 - val_accuracy: 0.9865 - val_precision: 0.9833 - val_recall: 0.6500\n",
      "Epoch 340/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0681 - accuracy: 0.9752 - precision: 0.8116 - recall: 0.4407 - val_loss: 0.0388 - val_accuracy: 0.9857 - val_precision: 0.9827 - val_recall: 0.6287\n",
      "Epoch 341/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0677 - accuracy: 0.9750 - precision: 0.8036 - recall: 0.4386 - val_loss: 0.0379 - val_accuracy: 0.9861 - val_precision: 0.9742 - val_recall: 0.6447\n",
      "Epoch 342/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0682 - accuracy: 0.9751 - precision: 0.8119 - recall: 0.4373 - val_loss: 0.0389 - val_accuracy: 0.9854 - val_precision: 0.9815 - val_recall: 0.6230\n",
      "Epoch 343/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0686 - accuracy: 0.9752 - precision: 0.8146 - recall: 0.4377 - val_loss: 0.0387 - val_accuracy: 0.9858 - val_precision: 0.9775 - val_recall: 0.6340\n",
      "Epoch 344/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0685 - accuracy: 0.9752 - precision: 0.8121 - recall: 0.4404 - val_loss: 0.0378 - val_accuracy: 0.9854 - val_precision: 0.9750 - val_recall: 0.6251\n",
      "Epoch 345/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0680 - accuracy: 0.9751 - precision: 0.8083 - recall: 0.4396 - val_loss: 0.0378 - val_accuracy: 0.9858 - val_precision: 0.9714 - val_recall: 0.6408\n",
      "Epoch 346/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0684 - accuracy: 0.9751 - precision: 0.8099 - recall: 0.4362 - val_loss: 0.0377 - val_accuracy: 0.9865 - val_precision: 0.9736 - val_recall: 0.6561\n",
      "Epoch 347/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0685 - accuracy: 0.9750 - precision: 0.8054 - recall: 0.4396 - val_loss: 0.0385 - val_accuracy: 0.9854 - val_precision: 0.9714 - val_recall: 0.6294\n",
      "Epoch 348/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0679 - accuracy: 0.9754 - precision: 0.8116 - recall: 0.4456 - val_loss: 0.0375 - val_accuracy: 0.9860 - val_precision: 0.9690 - val_recall: 0.6461\n",
      "Epoch 349/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0682 - accuracy: 0.9750 - precision: 0.8072 - recall: 0.4372 - val_loss: 0.0371 - val_accuracy: 0.9861 - val_precision: 0.9820 - val_recall: 0.6415\n",
      "Epoch 350/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0674 - accuracy: 0.9752 - precision: 0.8098 - recall: 0.4411 - val_loss: 0.0384 - val_accuracy: 0.9854 - val_precision: 0.9798 - val_recall: 0.6219\n",
      "Epoch 351/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0679 - accuracy: 0.9752 - precision: 0.8092 - recall: 0.4418 - val_loss: 0.0389 - val_accuracy: 0.9855 - val_precision: 0.9783 - val_recall: 0.6258\n",
      "Epoch 352/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0677 - accuracy: 0.9753 - precision: 0.8087 - recall: 0.4458 - val_loss: 0.0389 - val_accuracy: 0.9851 - val_precision: 0.9879 - val_recall: 0.6094\n",
      "Epoch 353/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0685 - accuracy: 0.9749 - precision: 0.8062 - recall: 0.4336 - val_loss: 0.0379 - val_accuracy: 0.9863 - val_precision: 0.9811 - val_recall: 0.6461\n",
      "Epoch 354/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0674 - accuracy: 0.9754 - precision: 0.8157 - recall: 0.4423 - val_loss: 0.0380 - val_accuracy: 0.9856 - val_precision: 0.9810 - val_recall: 0.6272\n",
      "Epoch 355/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0682 - accuracy: 0.9751 - precision: 0.8068 - recall: 0.4415 - val_loss: 0.0379 - val_accuracy: 0.9859 - val_precision: 0.9694 - val_recall: 0.6433\n",
      "Epoch 356/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0678 - accuracy: 0.9751 - precision: 0.8055 - recall: 0.4422 - val_loss: 0.0370 - val_accuracy: 0.9867 - val_precision: 0.9665 - val_recall: 0.6679\n",
      "Epoch 357/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0677 - accuracy: 0.9753 - precision: 0.8119 - recall: 0.4421 - val_loss: 0.0366 - val_accuracy: 0.9866 - val_precision: 0.9674 - val_recall: 0.6657\n",
      "Epoch 358/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0675 - accuracy: 0.9752 - precision: 0.8032 - recall: 0.4486 - val_loss: 0.0398 - val_accuracy: 0.9846 - val_precision: 0.9797 - val_recall: 0.6016\n",
      "Epoch 359/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0684 - accuracy: 0.9751 - precision: 0.8100 - recall: 0.4384 - val_loss: 0.0378 - val_accuracy: 0.9862 - val_precision: 0.9737 - val_recall: 0.6475\n",
      "Epoch 360/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0682 - accuracy: 0.9749 - precision: 0.8050 - recall: 0.4344 - val_loss: 0.0375 - val_accuracy: 0.9858 - val_precision: 0.9749 - val_recall: 0.6368\n",
      "Epoch 361/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0682 - accuracy: 0.9751 - precision: 0.8053 - recall: 0.4420 - val_loss: 0.0376 - val_accuracy: 0.9860 - val_precision: 0.9756 - val_recall: 0.6408\n",
      "Epoch 362/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0676 - accuracy: 0.9754 - precision: 0.8177 - recall: 0.4429 - val_loss: 0.0372 - val_accuracy: 0.9864 - val_precision: 0.9776 - val_recall: 0.6529\n",
      "Epoch 363/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0677 - accuracy: 0.9750 - precision: 0.8068 - recall: 0.4369 - val_loss: 0.0372 - val_accuracy: 0.9857 - val_precision: 0.9828 - val_recall: 0.6301\n",
      "Epoch 364/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0681 - accuracy: 0.9753 - precision: 0.8150 - recall: 0.4388 - val_loss: 0.0389 - val_accuracy: 0.9849 - val_precision: 0.9872 - val_recall: 0.6055\n",
      "Epoch 365/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0676 - accuracy: 0.9752 - precision: 0.8095 - recall: 0.4429 - val_loss: 0.0365 - val_accuracy: 0.9864 - val_precision: 0.9781 - val_recall: 0.6515\n",
      "Epoch 366/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0669 - accuracy: 0.9753 - precision: 0.8140 - recall: 0.4425 - val_loss: 0.0375 - val_accuracy: 0.9858 - val_precision: 0.9807 - val_recall: 0.6326\n",
      "Epoch 367/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0678 - accuracy: 0.9753 - precision: 0.8129 - recall: 0.4420 - val_loss: 0.0386 - val_accuracy: 0.9860 - val_precision: 0.9835 - val_recall: 0.6376\n",
      "Epoch 368/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0672 - accuracy: 0.9753 - precision: 0.8086 - recall: 0.4449 - val_loss: 0.0369 - val_accuracy: 0.9860 - val_precision: 0.9782 - val_recall: 0.6401\n",
      "Epoch 369/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0680 - accuracy: 0.9752 - precision: 0.8099 - recall: 0.4414 - val_loss: 0.0371 - val_accuracy: 0.9860 - val_precision: 0.9741 - val_recall: 0.6426\n",
      "Epoch 370/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0685 - accuracy: 0.9748 - precision: 0.8032 - recall: 0.4331 - val_loss: 0.0389 - val_accuracy: 0.9855 - val_precision: 0.9870 - val_recall: 0.6215\n",
      "Epoch 371/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0684 - accuracy: 0.9752 - precision: 0.8100 - recall: 0.4395 - val_loss: 0.0371 - val_accuracy: 0.9864 - val_precision: 0.9853 - val_recall: 0.6468\n",
      "Epoch 372/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0671 - accuracy: 0.9753 - precision: 0.8133 - recall: 0.4423 - val_loss: 0.0373 - val_accuracy: 0.9863 - val_precision: 0.9853 - val_recall: 0.6447\n",
      "Epoch 373/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0680 - accuracy: 0.9750 - precision: 0.8059 - recall: 0.4380 - val_loss: 0.0387 - val_accuracy: 0.9850 - val_precision: 0.9901 - val_recall: 0.6062\n",
      "Epoch 374/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0679 - accuracy: 0.9751 - precision: 0.8063 - recall: 0.4413 - val_loss: 0.0380 - val_accuracy: 0.9860 - val_precision: 0.9872 - val_recall: 0.6344\n",
      "Epoch 375/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0678 - accuracy: 0.9753 - precision: 0.8096 - recall: 0.4443 - val_loss: 0.0375 - val_accuracy: 0.9863 - val_precision: 0.9795 - val_recall: 0.6465\n",
      "Epoch 376/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0678 - accuracy: 0.9751 - precision: 0.8094 - recall: 0.4382 - val_loss: 0.0364 - val_accuracy: 0.9868 - val_precision: 0.9725 - val_recall: 0.6671\n",
      "Epoch 377/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0681 - accuracy: 0.9751 - precision: 0.8088 - recall: 0.4384 - val_loss: 0.0358 - val_accuracy: 0.9864 - val_precision: 0.9735 - val_recall: 0.6557\n",
      "Epoch 378/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0672 - accuracy: 0.9755 - precision: 0.8133 - recall: 0.4482 - val_loss: 0.0370 - val_accuracy: 0.9860 - val_precision: 0.9793 - val_recall: 0.6397\n",
      "Epoch 379/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0677 - accuracy: 0.9751 - precision: 0.8063 - recall: 0.4421 - val_loss: 0.0375 - val_accuracy: 0.9856 - val_precision: 0.9816 - val_recall: 0.6265\n",
      "Epoch 380/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0677 - accuracy: 0.9754 - precision: 0.8136 - recall: 0.4449 - val_loss: 0.0374 - val_accuracy: 0.9859 - val_precision: 0.9761 - val_recall: 0.6397\n",
      "Epoch 381/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0683 - accuracy: 0.9748 - precision: 0.8040 - recall: 0.4315 - val_loss: 0.0387 - val_accuracy: 0.9857 - val_precision: 0.9838 - val_recall: 0.6283\n",
      "Epoch 382/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0679 - accuracy: 0.9751 - precision: 0.8070 - recall: 0.4417 - val_loss: 0.0374 - val_accuracy: 0.9853 - val_precision: 0.9813 - val_recall: 0.6180\n",
      "Epoch 383/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0677 - accuracy: 0.9750 - precision: 0.8114 - recall: 0.4341 - val_loss: 0.0391 - val_accuracy: 0.9856 - val_precision: 0.9854 - val_recall: 0.6237\n",
      "Epoch 384/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0677 - accuracy: 0.9753 - precision: 0.8075 - recall: 0.4465 - val_loss: 0.0379 - val_accuracy: 0.9855 - val_precision: 0.9778 - val_recall: 0.6276\n",
      "Epoch 385/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0680 - accuracy: 0.9752 - precision: 0.8181 - recall: 0.4339 - val_loss: 0.0372 - val_accuracy: 0.9860 - val_precision: 0.9803 - val_recall: 0.6401\n",
      "Epoch 386/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0677 - accuracy: 0.9751 - precision: 0.8043 - recall: 0.4434 - val_loss: 0.0369 - val_accuracy: 0.9869 - val_precision: 0.9770 - val_recall: 0.6650\n",
      "Epoch 387/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0678 - accuracy: 0.9754 - precision: 0.8136 - recall: 0.4440 - val_loss: 0.0380 - val_accuracy: 0.9861 - val_precision: 0.9789 - val_recall: 0.6433\n",
      "Epoch 388/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0676 - accuracy: 0.9755 - precision: 0.8120 - recall: 0.4510 - val_loss: 0.0371 - val_accuracy: 0.9868 - val_precision: 0.9651 - val_recall: 0.6703\n",
      "Epoch 389/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0673 - accuracy: 0.9753 - precision: 0.8144 - recall: 0.4401 - val_loss: 0.0374 - val_accuracy: 0.9858 - val_precision: 0.9839 - val_recall: 0.6319\n",
      "Epoch 390/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0678 - accuracy: 0.9750 - precision: 0.8032 - recall: 0.4398 - val_loss: 0.0373 - val_accuracy: 0.9858 - val_precision: 0.9781 - val_recall: 0.6361\n",
      "Epoch 391/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0673 - accuracy: 0.9754 - precision: 0.8140 - recall: 0.4453 - val_loss: 0.0381 - val_accuracy: 0.9866 - val_precision: 0.9787 - val_recall: 0.6561\n",
      "Epoch 392/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0674 - accuracy: 0.9753 - precision: 0.8088 - recall: 0.4458 - val_loss: 0.0380 - val_accuracy: 0.9859 - val_precision: 0.9829 - val_recall: 0.6340\n",
      "Epoch 393/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0677 - accuracy: 0.9750 - precision: 0.8057 - recall: 0.4367 - val_loss: 0.0383 - val_accuracy: 0.9859 - val_precision: 0.9856 - val_recall: 0.6322\n",
      "Epoch 394/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0666 - accuracy: 0.9755 - precision: 0.8134 - recall: 0.4475 - val_loss: 0.0379 - val_accuracy: 0.9856 - val_precision: 0.9827 - val_recall: 0.6269\n",
      "Epoch 395/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0679 - accuracy: 0.9752 - precision: 0.8115 - recall: 0.4408 - val_loss: 0.0365 - val_accuracy: 0.9867 - val_precision: 0.9835 - val_recall: 0.6568\n",
      "Epoch 396/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0681 - accuracy: 0.9754 - precision: 0.8152 - recall: 0.4429 - val_loss: 0.0368 - val_accuracy: 0.9864 - val_precision: 0.9724 - val_recall: 0.6540\n",
      "Epoch 397/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0672 - accuracy: 0.9752 - precision: 0.8110 - recall: 0.4416 - val_loss: 0.0363 - val_accuracy: 0.9863 - val_precision: 0.9810 - val_recall: 0.6454\n",
      "Epoch 398/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0675 - accuracy: 0.9752 - precision: 0.8056 - recall: 0.4431 - val_loss: 0.0362 - val_accuracy: 0.9870 - val_precision: 0.9761 - val_recall: 0.6682\n",
      "Epoch 399/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0672 - accuracy: 0.9752 - precision: 0.8059 - recall: 0.4447 - val_loss: 0.0370 - val_accuracy: 0.9865 - val_precision: 0.9896 - val_recall: 0.6458\n",
      "Epoch 400/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0676 - accuracy: 0.9753 - precision: 0.8135 - recall: 0.4426 - val_loss: 0.0366 - val_accuracy: 0.9864 - val_precision: 0.9848 - val_recall: 0.6479\n",
      "Epoch 401/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0678 - accuracy: 0.9752 - precision: 0.8081 - recall: 0.4424 - val_loss: 0.0373 - val_accuracy: 0.9865 - val_precision: 0.9849 - val_recall: 0.6490\n",
      "Epoch 402/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0671 - accuracy: 0.9756 - precision: 0.8169 - recall: 0.4494 - val_loss: 0.0366 - val_accuracy: 0.9860 - val_precision: 0.9772 - val_recall: 0.6418\n",
      "Epoch 403/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0671 - accuracy: 0.9753 - precision: 0.8068 - recall: 0.4471 - val_loss: 0.0365 - val_accuracy: 0.9858 - val_precision: 0.9786 - val_recall: 0.6344\n",
      "Epoch 404/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0675 - accuracy: 0.9753 - precision: 0.8164 - recall: 0.4392 - val_loss: 0.0372 - val_accuracy: 0.9865 - val_precision: 0.9751 - val_recall: 0.6557\n",
      "Epoch 405/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0674 - accuracy: 0.9753 - precision: 0.8116 - recall: 0.4432 - val_loss: 0.0378 - val_accuracy: 0.9862 - val_precision: 0.9836 - val_recall: 0.6411\n",
      "Epoch 406/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0674 - accuracy: 0.9754 - precision: 0.8179 - recall: 0.4420 - val_loss: 0.0390 - val_accuracy: 0.9861 - val_precision: 0.9820 - val_recall: 0.6401\n",
      "Epoch 407/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0673 - accuracy: 0.9750 - precision: 0.8051 - recall: 0.4387 - val_loss: 0.0366 - val_accuracy: 0.9861 - val_precision: 0.9778 - val_recall: 0.6443\n",
      "Epoch 408/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0675 - accuracy: 0.9754 - precision: 0.8147 - recall: 0.4421 - val_loss: 0.0367 - val_accuracy: 0.9859 - val_precision: 0.9824 - val_recall: 0.6358\n",
      "Epoch 409/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0675 - accuracy: 0.9752 - precision: 0.8081 - recall: 0.4443 - val_loss: 0.0377 - val_accuracy: 0.9857 - val_precision: 0.9817 - val_recall: 0.6294\n",
      "Epoch 410/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0667 - accuracy: 0.9755 - precision: 0.8158 - recall: 0.4478 - val_loss: 0.0367 - val_accuracy: 0.9862 - val_precision: 0.9778 - val_recall: 0.6447\n",
      "Epoch 411/500\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0672 - accuracy: 0.9752 - precision: 0.8094 - recall: 0.4412 - val_loss: 0.0364 - val_accuracy: 0.9858 - val_precision: 0.9688 - val_recall: 0.6422\n",
      "Epoch 412/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0673 - accuracy: 0.9754 - precision: 0.8118 - recall: 0.4458 - val_loss: 0.0371 - val_accuracy: 0.9863 - val_precision: 0.9848 - val_recall: 0.6450\n",
      "Epoch 413/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0675 - accuracy: 0.9755 - precision: 0.8131 - recall: 0.4480 - val_loss: 0.0364 - val_accuracy: 0.9865 - val_precision: 0.9859 - val_recall: 0.6479\n",
      "Epoch 414/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0668 - accuracy: 0.9758 - precision: 0.8200 - recall: 0.4536 - val_loss: 0.0366 - val_accuracy: 0.9866 - val_precision: 0.9828 - val_recall: 0.6522\n",
      "Epoch 415/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0674 - accuracy: 0.9753 - precision: 0.8106 - recall: 0.4439 - val_loss: 0.0365 - val_accuracy: 0.9854 - val_precision: 0.9831 - val_recall: 0.6219\n",
      "Epoch 416/500\n",
      "600/600 [==============================] - 29s 49ms/step - loss: 0.0664 - accuracy: 0.9754 - precision: 0.8117 - recall: 0.4475 - val_loss: 0.0368 - val_accuracy: 0.9859 - val_precision: 0.9705 - val_recall: 0.6440\n",
      "Epoch 417/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0671 - accuracy: 0.9755 - precision: 0.8128 - recall: 0.4506 - val_loss: 0.0359 - val_accuracy: 0.9866 - val_precision: 0.9813 - val_recall: 0.6536\n",
      "Epoch 418/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0673 - accuracy: 0.9754 - precision: 0.8160 - recall: 0.4440 - val_loss: 0.0367 - val_accuracy: 0.9864 - val_precision: 0.9791 - val_recall: 0.6504\n",
      "Epoch 419/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0673 - accuracy: 0.9754 - precision: 0.8101 - recall: 0.4465 - val_loss: 0.0372 - val_accuracy: 0.9863 - val_precision: 0.9800 - val_recall: 0.6475\n",
      "Epoch 420/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0670 - accuracy: 0.9756 - precision: 0.8165 - recall: 0.4495 - val_loss: 0.0366 - val_accuracy: 0.9861 - val_precision: 0.9737 - val_recall: 0.6461\n",
      "Epoch 421/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0672 - accuracy: 0.9753 - precision: 0.8082 - recall: 0.4475 - val_loss: 0.0366 - val_accuracy: 0.9857 - val_precision: 0.9811 - val_recall: 0.6294\n",
      "Epoch 422/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0674 - accuracy: 0.9754 - precision: 0.8142 - recall: 0.4434 - val_loss: 0.0387 - val_accuracy: 0.9860 - val_precision: 0.9856 - val_recall: 0.6358\n",
      "Epoch 423/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0674 - accuracy: 0.9754 - precision: 0.8120 - recall: 0.4448 - val_loss: 0.0377 - val_accuracy: 0.9856 - val_precision: 0.9810 - val_recall: 0.6272\n",
      "Epoch 424/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0672 - accuracy: 0.9755 - precision: 0.8160 - recall: 0.4463 - val_loss: 0.0363 - val_accuracy: 0.9868 - val_precision: 0.9729 - val_recall: 0.6646\n",
      "Epoch 425/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0676 - accuracy: 0.9753 - precision: 0.8139 - recall: 0.4420 - val_loss: 0.0375 - val_accuracy: 0.9864 - val_precision: 0.9853 - val_recall: 0.6461\n",
      "Epoch 426/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0672 - accuracy: 0.9754 - precision: 0.8131 - recall: 0.4457 - val_loss: 0.0376 - val_accuracy: 0.9864 - val_precision: 0.9843 - val_recall: 0.6465\n",
      "Epoch 427/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0672 - accuracy: 0.9752 - precision: 0.8095 - recall: 0.4427 - val_loss: 0.0376 - val_accuracy: 0.9860 - val_precision: 0.9829 - val_recall: 0.6358\n",
      "Epoch 428/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0669 - accuracy: 0.9753 - precision: 0.8109 - recall: 0.4446 - val_loss: 0.0365 - val_accuracy: 0.9867 - val_precision: 0.9783 - val_recall: 0.6582\n",
      "Epoch 429/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0675 - accuracy: 0.9754 - precision: 0.8111 - recall: 0.4457 - val_loss: 0.0387 - val_accuracy: 0.9863 - val_precision: 0.9842 - val_recall: 0.6454\n",
      "Epoch 430/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0673 - accuracy: 0.9754 - precision: 0.8106 - recall: 0.4461 - val_loss: 0.0370 - val_accuracy: 0.9862 - val_precision: 0.9842 - val_recall: 0.6426\n",
      "Epoch 431/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0670 - accuracy: 0.9755 - precision: 0.8143 - recall: 0.4477 - val_loss: 0.0367 - val_accuracy: 0.9863 - val_precision: 0.9868 - val_recall: 0.6415\n",
      "Epoch 432/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0667 - accuracy: 0.9756 - precision: 0.8158 - recall: 0.4501 - val_loss: 0.0354 - val_accuracy: 0.9869 - val_precision: 0.9770 - val_recall: 0.6664\n",
      "Epoch 433/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0668 - accuracy: 0.9756 - precision: 0.8141 - recall: 0.4527 - val_loss: 0.0359 - val_accuracy: 0.9862 - val_precision: 0.9779 - val_recall: 0.6458\n",
      "Epoch 434/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0672 - accuracy: 0.9755 - precision: 0.8153 - recall: 0.4477 - val_loss: 0.0359 - val_accuracy: 0.9865 - val_precision: 0.9896 - val_recall: 0.6472\n",
      "Epoch 435/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0668 - accuracy: 0.9759 - precision: 0.8222 - recall: 0.4535 - val_loss: 0.0354 - val_accuracy: 0.9868 - val_precision: 0.9800 - val_recall: 0.6622\n",
      "Epoch 436/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0670 - accuracy: 0.9756 - precision: 0.8158 - recall: 0.4489 - val_loss: 0.0378 - val_accuracy: 0.9861 - val_precision: 0.9895 - val_recall: 0.6351\n",
      "Epoch 437/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0670 - accuracy: 0.9755 - precision: 0.8147 - recall: 0.4456 - val_loss: 0.0366 - val_accuracy: 0.9867 - val_precision: 0.9929 - val_recall: 0.6493\n",
      "Epoch 438/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0671 - accuracy: 0.9756 - precision: 0.8164 - recall: 0.4491 - val_loss: 0.0374 - val_accuracy: 0.9863 - val_precision: 0.9896 - val_recall: 0.6418\n",
      "Epoch 439/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0674 - accuracy: 0.9751 - precision: 0.8068 - recall: 0.4386 - val_loss: 0.0367 - val_accuracy: 0.9859 - val_precision: 0.9877 - val_recall: 0.6304\n",
      "Epoch 440/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0670 - accuracy: 0.9756 - precision: 0.8182 - recall: 0.4471 - val_loss: 0.0358 - val_accuracy: 0.9865 - val_precision: 0.9807 - val_recall: 0.6529\n",
      "Epoch 441/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0669 - accuracy: 0.9754 - precision: 0.8113 - recall: 0.4478 - val_loss: 0.0366 - val_accuracy: 0.9868 - val_precision: 0.9830 - val_recall: 0.6589\n",
      "Epoch 442/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0666 - accuracy: 0.9756 - precision: 0.8137 - recall: 0.4529 - val_loss: 0.0373 - val_accuracy: 0.9861 - val_precision: 0.9830 - val_recall: 0.6386\n",
      "Epoch 443/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0671 - accuracy: 0.9755 - precision: 0.8129 - recall: 0.4479 - val_loss: 0.0377 - val_accuracy: 0.9860 - val_precision: 0.9856 - val_recall: 0.6351\n",
      "Epoch 444/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0671 - accuracy: 0.9755 - precision: 0.8155 - recall: 0.4458 - val_loss: 0.0365 - val_accuracy: 0.9866 - val_precision: 0.9829 - val_recall: 0.6547\n",
      "Epoch 445/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0678 - accuracy: 0.9750 - precision: 0.8114 - recall: 0.4341 - val_loss: 0.0358 - val_accuracy: 0.9868 - val_precision: 0.9810 - val_recall: 0.6607\n",
      "Epoch 446/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0675 - accuracy: 0.9753 - precision: 0.8101 - recall: 0.4447 - val_loss: 0.0375 - val_accuracy: 0.9858 - val_precision: 0.9844 - val_recall: 0.6308\n",
      "Epoch 447/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0666 - accuracy: 0.9757 - precision: 0.8219 - recall: 0.4478 - val_loss: 0.0362 - val_accuracy: 0.9865 - val_precision: 0.9802 - val_recall: 0.6529\n",
      "Epoch 448/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0665 - accuracy: 0.9756 - precision: 0.8165 - recall: 0.4495 - val_loss: 0.0380 - val_accuracy: 0.9857 - val_precision: 0.9855 - val_recall: 0.6283\n",
      "Epoch 449/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0676 - accuracy: 0.9752 - precision: 0.8078 - recall: 0.4434 - val_loss: 0.0370 - val_accuracy: 0.9860 - val_precision: 0.9830 - val_recall: 0.6383\n",
      "Epoch 450/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0669 - accuracy: 0.9754 - precision: 0.8156 - recall: 0.4430 - val_loss: 0.0374 - val_accuracy: 0.9860 - val_precision: 0.9846 - val_recall: 0.6372\n",
      "Epoch 451/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0664 - accuracy: 0.9755 - precision: 0.8127 - recall: 0.4501 - val_loss: 0.0357 - val_accuracy: 0.9863 - val_precision: 0.9842 - val_recall: 0.6436\n",
      "Epoch 452/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0675 - accuracy: 0.9752 - precision: 0.8095 - recall: 0.4405 - val_loss: 0.0355 - val_accuracy: 0.9871 - val_precision: 0.9767 - val_recall: 0.6714\n",
      "Epoch 453/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0667 - accuracy: 0.9757 - precision: 0.8151 - recall: 0.4525 - val_loss: 0.0377 - val_accuracy: 0.9860 - val_precision: 0.9835 - val_recall: 0.6368\n",
      "Epoch 454/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0675 - accuracy: 0.9755 - precision: 0.8180 - recall: 0.4444 - val_loss: 0.0368 - val_accuracy: 0.9861 - val_precision: 0.9846 - val_recall: 0.6379\n",
      "Epoch 455/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0672 - accuracy: 0.9756 - precision: 0.8130 - recall: 0.4505 - val_loss: 0.0378 - val_accuracy: 0.9852 - val_precision: 0.9890 - val_recall: 0.6112\n",
      "Epoch 456/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0666 - accuracy: 0.9757 - precision: 0.8175 - recall: 0.4533 - val_loss: 0.0363 - val_accuracy: 0.9865 - val_precision: 0.9812 - val_recall: 0.6511\n",
      "Epoch 457/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0676 - accuracy: 0.9755 - precision: 0.8196 - recall: 0.4437 - val_loss: 0.0353 - val_accuracy: 0.9862 - val_precision: 0.9774 - val_recall: 0.6465\n",
      "Epoch 458/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0676 - accuracy: 0.9754 - precision: 0.8153 - recall: 0.4420 - val_loss: 0.0362 - val_accuracy: 0.9868 - val_precision: 0.9759 - val_recall: 0.6643\n",
      "Epoch 459/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0665 - accuracy: 0.9754 - precision: 0.8114 - recall: 0.4453 - val_loss: 0.0353 - val_accuracy: 0.9865 - val_precision: 0.9849 - val_recall: 0.6504\n",
      "Epoch 460/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0670 - accuracy: 0.9755 - precision: 0.8152 - recall: 0.4469 - val_loss: 0.0373 - val_accuracy: 0.9860 - val_precision: 0.9883 - val_recall: 0.6340\n",
      "Epoch 461/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0668 - accuracy: 0.9756 - precision: 0.8133 - recall: 0.4521 - val_loss: 0.0360 - val_accuracy: 0.9868 - val_precision: 0.9825 - val_recall: 0.6593\n",
      "Epoch 462/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0663 - accuracy: 0.9755 - precision: 0.8110 - recall: 0.4498 - val_loss: 0.0359 - val_accuracy: 0.9861 - val_precision: 0.9799 - val_recall: 0.6422\n",
      "Epoch 463/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0675 - accuracy: 0.9750 - precision: 0.8087 - recall: 0.4349 - val_loss: 0.0359 - val_accuracy: 0.9870 - val_precision: 0.9811 - val_recall: 0.6650\n",
      "Epoch 464/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0675 - accuracy: 0.9752 - precision: 0.8056 - recall: 0.4446 - val_loss: 0.0372 - val_accuracy: 0.9861 - val_precision: 0.9884 - val_recall: 0.6368\n",
      "Epoch 465/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0671 - accuracy: 0.9754 - precision: 0.8155 - recall: 0.4439 - val_loss: 0.0368 - val_accuracy: 0.9860 - val_precision: 0.9867 - val_recall: 0.6347\n",
      "Epoch 466/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0671 - accuracy: 0.9755 - precision: 0.8127 - recall: 0.4494 - val_loss: 0.0359 - val_accuracy: 0.9867 - val_precision: 0.9788 - val_recall: 0.6579\n",
      "Epoch 467/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0673 - accuracy: 0.9753 - precision: 0.8086 - recall: 0.4445 - val_loss: 0.0383 - val_accuracy: 0.9858 - val_precision: 0.9828 - val_recall: 0.6319\n",
      "Epoch 468/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0664 - accuracy: 0.9756 - precision: 0.8146 - recall: 0.4506 - val_loss: 0.0375 - val_accuracy: 0.9859 - val_precision: 0.9883 - val_recall: 0.6297\n",
      "Epoch 469/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0668 - accuracy: 0.9755 - precision: 0.8164 - recall: 0.4466 - val_loss: 0.0357 - val_accuracy: 0.9862 - val_precision: 0.9884 - val_recall: 0.6386\n",
      "Epoch 470/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0670 - accuracy: 0.9756 - precision: 0.8142 - recall: 0.4512 - val_loss: 0.0354 - val_accuracy: 0.9869 - val_precision: 0.9676 - val_recall: 0.6714\n",
      "Epoch 471/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0661 - accuracy: 0.9756 - precision: 0.8162 - recall: 0.4510 - val_loss: 0.0356 - val_accuracy: 0.9863 - val_precision: 0.9858 - val_recall: 0.6440\n",
      "Epoch 472/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0667 - accuracy: 0.9755 - precision: 0.8110 - recall: 0.4503 - val_loss: 0.0370 - val_accuracy: 0.9856 - val_precision: 0.9865 - val_recall: 0.6244\n",
      "Epoch 473/500\n",
      "600/600 [==============================] - 29s 48ms/step - loss: 0.0671 - accuracy: 0.9755 - precision: 0.8143 - recall: 0.4468 - val_loss: 0.0368 - val_accuracy: 0.9864 - val_precision: 0.9858 - val_recall: 0.6450\n",
      "Epoch 474/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0672 - accuracy: 0.9755 - precision: 0.8107 - recall: 0.4494 - val_loss: 0.0362 - val_accuracy: 0.9863 - val_precision: 0.9699 - val_recall: 0.6540\n",
      "Epoch 475/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0668 - accuracy: 0.9752 - precision: 0.8104 - recall: 0.4409 - val_loss: 0.0359 - val_accuracy: 0.9865 - val_precision: 0.9838 - val_recall: 0.6493\n",
      "Epoch 476/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0669 - accuracy: 0.9755 - precision: 0.8147 - recall: 0.4461 - val_loss: 0.0357 - val_accuracy: 0.9866 - val_precision: 0.9870 - val_recall: 0.6500\n",
      "Epoch 477/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0668 - accuracy: 0.9755 - precision: 0.8152 - recall: 0.4456 - val_loss: 0.0356 - val_accuracy: 0.9861 - val_precision: 0.9691 - val_recall: 0.6490\n",
      "Epoch 478/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0664 - accuracy: 0.9758 - precision: 0.8168 - recall: 0.4544 - val_loss: 0.0351 - val_accuracy: 0.9867 - val_precision: 0.9840 - val_recall: 0.6561\n",
      "Epoch 479/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0669 - accuracy: 0.9753 - precision: 0.8123 - recall: 0.4433 - val_loss: 0.0362 - val_accuracy: 0.9862 - val_precision: 0.9884 - val_recall: 0.6393\n",
      "Epoch 480/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0668 - accuracy: 0.9758 - precision: 0.8192 - recall: 0.4535 - val_loss: 0.0354 - val_accuracy: 0.9867 - val_precision: 0.9824 - val_recall: 0.6561\n",
      "Epoch 481/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0663 - accuracy: 0.9758 - precision: 0.8160 - recall: 0.4551 - val_loss: 0.0354 - val_accuracy: 0.9865 - val_precision: 0.9672 - val_recall: 0.6622\n",
      "Epoch 482/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0668 - accuracy: 0.9758 - precision: 0.8170 - recall: 0.4543 - val_loss: 0.0380 - val_accuracy: 0.9853 - val_precision: 0.9841 - val_recall: 0.6165\n",
      "Epoch 483/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0666 - accuracy: 0.9757 - precision: 0.8168 - recall: 0.4507 - val_loss: 0.0363 - val_accuracy: 0.9862 - val_precision: 0.9820 - val_recall: 0.6422\n",
      "Epoch 484/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0667 - accuracy: 0.9755 - precision: 0.8158 - recall: 0.4473 - val_loss: 0.0360 - val_accuracy: 0.9868 - val_precision: 0.9779 - val_recall: 0.6614\n",
      "Epoch 485/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0670 - accuracy: 0.9755 - precision: 0.8135 - recall: 0.4487 - val_loss: 0.0361 - val_accuracy: 0.9864 - val_precision: 0.9838 - val_recall: 0.6483\n",
      "Epoch 486/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0667 - accuracy: 0.9757 - precision: 0.8152 - recall: 0.4520 - val_loss: 0.0373 - val_accuracy: 0.9861 - val_precision: 0.9867 - val_recall: 0.6365\n",
      "Epoch 487/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0672 - accuracy: 0.9755 - precision: 0.8167 - recall: 0.4470 - val_loss: 0.0357 - val_accuracy: 0.9870 - val_precision: 0.9847 - val_recall: 0.6636\n",
      "Epoch 488/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0668 - accuracy: 0.9755 - precision: 0.8111 - recall: 0.4494 - val_loss: 0.0365 - val_accuracy: 0.9867 - val_precision: 0.9834 - val_recall: 0.6565\n",
      "Epoch 489/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0672 - accuracy: 0.9755 - precision: 0.8154 - recall: 0.4469 - val_loss: 0.0347 - val_accuracy: 0.9871 - val_precision: 0.9832 - val_recall: 0.6657\n",
      "Epoch 490/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0670 - accuracy: 0.9756 - precision: 0.8135 - recall: 0.4517 - val_loss: 0.0362 - val_accuracy: 0.9868 - val_precision: 0.9850 - val_recall: 0.6561\n",
      "Epoch 491/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0666 - accuracy: 0.9757 - precision: 0.8152 - recall: 0.4527 - val_loss: 0.0353 - val_accuracy: 0.9865 - val_precision: 0.9833 - val_recall: 0.6493\n",
      "Epoch 492/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0669 - accuracy: 0.9755 - precision: 0.8137 - recall: 0.4476 - val_loss: 0.0358 - val_accuracy: 0.9872 - val_precision: 0.9798 - val_recall: 0.6728\n",
      "Epoch 493/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0667 - accuracy: 0.9756 - precision: 0.8137 - recall: 0.4518 - val_loss: 0.0353 - val_accuracy: 0.9869 - val_precision: 0.9780 - val_recall: 0.6646\n",
      "Epoch 494/500\n",
      "600/600 [==============================] - 28s 47ms/step - loss: 0.0669 - accuracy: 0.9755 - precision: 0.8157 - recall: 0.4459 - val_loss: 0.0356 - val_accuracy: 0.9875 - val_precision: 0.9799 - val_recall: 0.6789\n",
      "Epoch 495/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0662 - accuracy: 0.9758 - precision: 0.8131 - recall: 0.4578 - val_loss: 0.0359 - val_accuracy: 0.9867 - val_precision: 0.9819 - val_recall: 0.6579\n",
      "Epoch 496/500\n",
      "600/600 [==============================] - 27s 45ms/step - loss: 0.0671 - accuracy: 0.9755 - precision: 0.8132 - recall: 0.4485 - val_loss: 0.0361 - val_accuracy: 0.9867 - val_precision: 0.9887 - val_recall: 0.6522\n",
      "Epoch 497/500\n",
      "600/600 [==============================] - 27s 46ms/step - loss: 0.0663 - accuracy: 0.9759 - precision: 0.8236 - recall: 0.4522 - val_loss: 0.0355 - val_accuracy: 0.9875 - val_precision: 0.9839 - val_recall: 0.6764\n",
      "Epoch 498/500\n",
      "600/600 [==============================] - 30s 50ms/step - loss: 0.0668 - accuracy: 0.9755 - precision: 0.8119 - recall: 0.4490 - val_loss: 0.0373 - val_accuracy: 0.9859 - val_precision: 0.9877 - val_recall: 0.6304\n",
      "Epoch 499/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0670 - accuracy: 0.9757 - precision: 0.8192 - recall: 0.4508 - val_loss: 0.0374 - val_accuracy: 0.9858 - val_precision: 0.9866 - val_recall: 0.6287\n",
      "Epoch 500/500\n",
      "600/600 [==============================] - 28s 46ms/step - loss: 0.0673 - accuracy: 0.9755 - precision: 0.8163 - recall: 0.4451 - val_loss: 0.0368 - val_accuracy: 0.9863 - val_precision: 0.9800 - val_recall: 0.6475\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=epochs,batch_size=500, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities for test set\n",
    "yhat_probs = model.predict(X_test, verbose=0)\n",
    "# reduce to 1d array\n",
    "yhat_probs = yhat_probs[:, 0]> 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.986314\n",
      "Precision: 0.980043\n",
      "Recall: 0.647541\n",
      "f1: 0.779828\n",
      "auc_score: 0.823514\n"
     ]
    }
   ],
   "source": [
    "# demonstration of calculating metrics for a neural network model using sklearn\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# accuracy: (tp + tn) / (p + n)\n",
    "accuracy = accuracy_score(y_test, yhat_probs)\n",
    "print('Accuracy: %f' % accuracy)\n",
    "# precision tp / (tp + fp)\n",
    "precision = precision_score(y_test, yhat_probs)\n",
    "print('Precision: %f' % precision)\n",
    "# recall: tp / (tp + fn)\n",
    "recall = recall_score(y_test, yhat_probs)\n",
    "print('Recall: %f' % recall)\n",
    "f1 = f1_score(y_test, yhat_probs)\n",
    "print('f1: %f' % f1)\n",
    "auc_score=roc_auc_score(y_test, yhat_probs)\n",
    "print('auc_score: %f' % auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "8kJdIQ2Eezf7"
   },
   "outputs": [],
   "source": [
    "def plot_learningCurve(history, epoch):\n",
    "  # Plot training & validation accuracy values\n",
    "  epoch_range = range(1, epoch+1)\n",
    "  plt.plot(epoch_range, history.history['accuracy'])\n",
    "  plt.plot(epoch_range, history.history['val_accuracy'])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot training & validation loss values\n",
    "  plt.plot(epoch_range, history.history['loss'])\n",
    "  plt.plot(epoch_range, history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "JVOLDktEezf7",
    "outputId": "2610cd95-3f62-4079-c4a1-0988d69165ce"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_learningCurve(history, epochs)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "408d89a3b80ac34e5cdc914373b09bb69ba3e3a6a7f756d6d7498fd367058138"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 1,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
